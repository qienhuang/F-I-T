{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Referential IO Demo: Coherence Gate vs Uncontrolled Tempo\n",
    "\n",
    "This notebook demonstrates why **self-referential AI capabilities** (tool loops, self-eval gates) require governance controls.\n",
    "\n",
    "We compare two scenarios:\n",
    "- **Scenario A**: No coherence gate → tempo amplification → validation lag explodes\n",
    "- **Scenario B**: P10-style coherence gate → tempo controlled → metrics stable\n",
    "\n",
    "**Runtime**: < 1 minute, no GPU required.\n",
    "\n",
    "**Reference**: [S-RIOCS Standard](../docs/ai_safety/self_referential_io.md) | [FIT v2.4](../docs/v2.4.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0: Dependencies (standard library + matplotlib/numpy)\n",
    "# pip install matplotlib numpy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Tuple\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Dependencies loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Metrics Tracker (VL / RDPR / GBR)\n",
    "\n",
    "@dataclass\n",
    "class MetricsTracker:\n",
    "    \"\"\"Tracks the three governance metrics from S-RIOCS.\"\"\"\n",
    "    \n",
    "    validation_lag: List[float] = field(default_factory=list)  # VL: hours since change, before eval closes\n",
    "    rollback_feasibility: List[float] = field(default_factory=list)  # Proxy for RDPR (0-1 scale)\n",
    "    gate_bypass_events: List[int] = field(default_factory=list)  # Cumulative bypass count\n",
    "    tempo: List[float] = field(default_factory=list)  # Cycle time (lower = faster)\n",
    "    \n",
    "    _cumulative_bypass: int = 0\n",
    "    \n",
    "    def record(self, vl: float, rollback_feas: float, bypassed: bool, cycle_time: float):\n",
    "        self.validation_lag.append(vl)\n",
    "        self.rollback_feasibility.append(rollback_feas)\n",
    "        if bypassed:\n",
    "            self._cumulative_bypass += 1\n",
    "        self.gate_bypass_events.append(self._cumulative_bypass)\n",
    "        self.tempo.append(cycle_time)\n",
    "    \n",
    "    def summary(self) -> dict:\n",
    "        return {\n",
    "            \"final_VL\": self.validation_lag[-1] if self.validation_lag else 0,\n",
    "            \"mean_VL\": np.mean(self.validation_lag) if self.validation_lag else 0,\n",
    "            \"final_rollback_feasibility\": self.rollback_feasibility[-1] if self.rollback_feasibility else 1,\n",
    "            \"total_bypasses\": self._cumulative_bypass,\n",
    "            \"final_tempo\": self.tempo[-1] if self.tempo else 1,\n",
    "        }\n",
    "\n",
    "print(\"MetricsTracker defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Self-Referential Agent\n",
    "\n",
    "@dataclass\n",
    "class SelfReferentialAgent:\n",
    "    \"\"\"\n",
    "    A toy agent with self-eval and tool-loop capabilities.\n",
    "    \n",
    "    - self_eval(): produces a confidence score (may have self-confirmation bias)\n",
    "    - tool_call(): simulates external action, may trigger more loops\n",
    "    - coherence_gate(): P10-style multi-estimator agreement check\n",
    "    \"\"\"\n",
    "    \n",
    "    use_coherence_gate: bool = False\n",
    "    coherence_threshold: float = 0.3  # Max allowed disagreement between estimators\n",
    "    \n",
    "    # Internal state\n",
    "    confidence: float = 0.5\n",
    "    action_count: int = 0\n",
    "    loop_depth: int = 0\n",
    "    max_loop_depth: int = 10  # Hard limit (only enforced if gate is on)\n",
    "    \n",
    "    # Self-confirmation bias strength (0 = no bias, 1 = full bias)\n",
    "    self_confirmation_bias: float = 0.3\n",
    "    \n",
    "    def self_eval(self) -> float:\n",
    "        \"\"\"\n",
    "        Self-evaluation with potential confirmation bias.\n",
    "        Returns confidence score [0, 1].\n",
    "        \"\"\"\n",
    "        # Base evaluation (noisy)\n",
    "        true_signal = 0.5 + 0.1 * np.sin(self.action_count * 0.1)\n",
    "        noise = np.random.normal(0, 0.1)\n",
    "        \n",
    "        # Self-confirmation bias: tends to confirm current confidence\n",
    "        biased_eval = (\n",
    "            (1 - self.self_confirmation_bias) * (true_signal + noise) +\n",
    "            self.self_confirmation_bias * self.confidence\n",
    "        )\n",
    "        \n",
    "        return np.clip(biased_eval, 0, 1)\n",
    "    \n",
    "    def external_eval(self) -> float:\n",
    "        \"\"\"\n",
    "        Independent external evaluation (no self-confirmation bias).\n",
    "        Used as second estimator in coherence gate.\n",
    "        \"\"\"\n",
    "        true_signal = 0.5 + 0.1 * np.sin(self.action_count * 0.1)\n",
    "        noise = np.random.normal(0, 0.15)  # Slightly noisier\n",
    "        return np.clip(true_signal + noise, 0, 1)\n",
    "    \n",
    "    def coherence_gate(self) -> Tuple[bool, float]:\n",
    "        \"\"\"\n",
    "        P10-style coherence gate: check if multiple estimators agree.\n",
    "        Returns (passed, disagreement_score).\n",
    "        \"\"\"\n",
    "        self_score = self.self_eval()\n",
    "        external_score = self.external_eval()\n",
    "        disagreement = abs(self_score - external_score)\n",
    "        \n",
    "        passed = disagreement <= self.coherence_threshold\n",
    "        return passed, disagreement\n",
    "    \n",
    "    def tool_call(self) -> bool:\n",
    "        \"\"\"\n",
    "        Simulate a tool call / action.\n",
    "        Returns True if action was taken.\n",
    "        \"\"\"\n",
    "        self.action_count += 1\n",
    "        self.loop_depth += 1\n",
    "        \n",
    "        # Action affects confidence (feedback loop)\n",
    "        self.confidence = 0.7 * self.confidence + 0.3 * self.self_eval()\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def should_continue_loop(self) -> bool:\n",
    "        \"\"\"\n",
    "        Decide whether to continue the tool loop.\n",
    "        Without gate: continues if self-eval is high enough.\n",
    "        With gate: also checks coherence and depth limit.\n",
    "        \"\"\"\n",
    "        self_score = self.self_eval()\n",
    "        \n",
    "        if self.use_coherence_gate:\n",
    "            # Check depth limit\n",
    "            if self.loop_depth >= self.max_loop_depth:\n",
    "                return False\n",
    "            \n",
    "            # Check coherence\n",
    "            passed, _ = self.coherence_gate()\n",
    "            if not passed:\n",
    "                return False\n",
    "            \n",
    "            return self_score > 0.4\n",
    "        else:\n",
    "            # No gate: just use self-eval (self-confirmation prone)\n",
    "            return self_score > 0.3  # Lower threshold = more likely to continue\n",
    "    \n",
    "    def reset_loop(self):\n",
    "        \"\"\"Reset loop depth for new decision cycle.\"\"\"\n",
    "        self.loop_depth = 0\n",
    "\n",
    "print(\"SelfReferentialAgent defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Simulation Runner\n",
    "\n",
    "def run_simulation(\n",
    "    agent: SelfReferentialAgent,\n",
    "    num_steps: int = 100,\n",
    "    base_cycle_time: float = 1.0,\n",
    "    base_validation_time: float = 2.0,\n",
    ") -> MetricsTracker:\n",
    "    \"\"\"\n",
    "    Run simulation and track metrics.\n",
    "    \n",
    "    Key dynamics:\n",
    "    - Without gate: cycle time decreases (tempo amplification), VL increases\n",
    "    - With gate: cycle time bounded, VL stable\n",
    "    \"\"\"\n",
    "    tracker = MetricsTracker()\n",
    "    \n",
    "    cycle_time = base_cycle_time\n",
    "    validation_backlog = 0.0\n",
    "    rollback_feasibility = 1.0\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        agent.reset_loop()\n",
    "        \n",
    "        # Inner loop: agent decides how many tool calls to make\n",
    "        loop_actions = 0\n",
    "        while agent.should_continue_loop():\n",
    "            agent.tool_call()\n",
    "            loop_actions += 1\n",
    "            \n",
    "            # Safety break for uncontrolled case\n",
    "            if loop_actions > 50:\n",
    "                break\n",
    "        \n",
    "        # Tempo dynamics\n",
    "        if agent.use_coherence_gate:\n",
    "            # Gate keeps tempo bounded\n",
    "            cycle_time = max(0.5, base_cycle_time - 0.01 * step + np.random.normal(0, 0.05))\n",
    "        else:\n",
    "            # No gate: tempo accelerates (cycle time shrinks)\n",
    "            acceleration = 0.02 * (1 + loop_actions * 0.1)\n",
    "            cycle_time = max(0.1, cycle_time - acceleration + np.random.normal(0, 0.02))\n",
    "        \n",
    "        # Validation lag dynamics\n",
    "        # VL increases when cycle_time < validation processing rate\n",
    "        validation_processed = base_validation_time * 0.8  # Validation team capacity\n",
    "        changes_produced = 1.0 / max(cycle_time, 0.1)  # Changes per unit time\n",
    "        \n",
    "        if changes_produced > validation_processed:\n",
    "            validation_backlog += (changes_produced - validation_processed) * 0.5\n",
    "        else:\n",
    "            validation_backlog = max(0, validation_backlog - 0.3)\n",
    "        \n",
    "        current_vl = validation_backlog + cycle_time  # VL = backlog + current cycle\n",
    "        \n",
    "        # Rollback feasibility decreases with accumulated unvalidated changes\n",
    "        if agent.use_coherence_gate:\n",
    "            rollback_feasibility = max(0.6, 1.0 - 0.002 * step + np.random.normal(0, 0.02))\n",
    "        else:\n",
    "            rollback_feasibility = max(0.1, rollback_feasibility - 0.005 * loop_actions + np.random.normal(0, 0.01))\n",
    "        \n",
    "        # Bypass detection (only relevant for gated case)\n",
    "        bypassed = False\n",
    "        if agent.use_coherence_gate:\n",
    "            # Occasionally someone might bypass (low probability if gate is on)\n",
    "            bypassed = random.random() < 0.01\n",
    "        else:\n",
    "            # No gate = everything is effectively a bypass\n",
    "            bypassed = loop_actions > 5  # Flag excessive loops as implicit bypass\n",
    "        \n",
    "        tracker.record(\n",
    "            vl=current_vl,\n",
    "            rollback_feas=rollback_feasibility,\n",
    "            bypassed=bypassed,\n",
    "            cycle_time=cycle_time\n",
    "        )\n",
    "    \n",
    "    return tracker\n",
    "\n",
    "print(\"Simulation runner defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Run Scenario A - No Coherence Gate\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SCENARIO A: No Coherence Gate\")\n",
    "print(\"Self-eval directly gates actions, no multi-estimator check\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "agent_a = SelfReferentialAgent(\n",
    "    use_coherence_gate=False,\n",
    "    self_confirmation_bias=0.4,  # Moderate bias\n",
    ")\n",
    "\n",
    "tracker_a = run_simulation(agent_a, num_steps=100)\n",
    "\n",
    "summary_a = tracker_a.summary()\n",
    "print(f\"\\nResults after 100 steps:\")\n",
    "print(f\"  Final Validation Lag: {summary_a['final_VL']:.2f} hours\")\n",
    "print(f\"  Mean Validation Lag:  {summary_a['mean_VL']:.2f} hours\")\n",
    "print(f\"  Rollback Feasibility: {summary_a['final_rollback_feasibility']:.2%}\")\n",
    "print(f\"  Total Bypass Events:  {summary_a['total_bypasses']}\")\n",
    "print(f\"  Final Cycle Time:     {summary_a['final_tempo']:.3f} (lower = faster tempo)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Run Scenario B - With P10 Coherence Gate\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SCENARIO B: With P10-Style Coherence Gate\")\n",
    "print(\"Multi-estimator agreement required, loop depth bounded\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "agent_b = SelfReferentialAgent(\n",
    "    use_coherence_gate=True,\n",
    "    coherence_threshold=0.3,\n",
    "    max_loop_depth=10,\n",
    "    self_confirmation_bias=0.4,  # Same bias, but gate catches it\n",
    ")\n",
    "\n",
    "# Reset random seed for fair comparison\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "tracker_b = run_simulation(agent_b, num_steps=100)\n",
    "\n",
    "summary_b = tracker_b.summary()\n",
    "print(f\"\\nResults after 100 steps:\")\n",
    "print(f\"  Final Validation Lag: {summary_b['final_VL']:.2f} hours\")\n",
    "print(f\"  Mean Validation Lag:  {summary_b['mean_VL']:.2f} hours\")\n",
    "print(f\"  Rollback Feasibility: {summary_b['final_rollback_feasibility']:.2%}\")\n",
    "print(f\"  Total Bypass Events:  {summary_b['total_bypasses']}\")\n",
    "print(f\"  Final Cycle Time:     {summary_b['final_tempo']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 6: Visualization - Side by Side Comparison\nimport os\nimport random\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nrequired = ['SelfReferentialAgent', 'run_simulation']\nmissing = [name for name in required if name not in globals()]\nif missing:\n    raise RuntimeError(\n        'Missing definitions: ' + ', '.join(missing) + '. Run Cells 0-3 first (or use Run All).'\n    )\n\ntracker_a = globals().get('tracker_a')\nif tracker_a is None:\n    print(\"tracker_a not found; running Scenario A (No Gate) for plotting...\")\n    random.seed(42)\n    np.random.seed(42)\n    agent_a = SelfReferentialAgent(\n        use_coherence_gate=False,\n        self_confirmation_bias=0.4,\n    )\n    tracker_a = run_simulation(agent_a, num_steps=100)\n    globals()['tracker_a'] = tracker_a\n    globals()['summary_a'] = tracker_a.summary()\n\ntracker_b = globals().get('tracker_b')\nif tracker_b is None:\n    print(\"tracker_b not found; running Scenario B (With Gate) for plotting...\")\n    random.seed(42)\n    np.random.seed(42)\n    agent_b = SelfReferentialAgent(\n        use_coherence_gate=True,\n        coherence_threshold=0.3,\n        max_loop_depth=10,\n        self_confirmation_bias=0.4,\n    )\n    tracker_b = run_simulation(agent_b, num_steps=100)\n    globals()['tracker_b'] = tracker_b\n    globals()['summary_b'] = tracker_b.summary()\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\nfig.suptitle('Self-Referential Agent: No Gate vs P10 Coherence Gate', fontsize=14, fontweight='bold')\n\nsteps = range(len(tracker_a.validation_lag))\n\n# Top Left: Tempo (Cycle Time)\nax1 = axes[0, 0]\nax1.plot(steps, tracker_a.tempo, 'r-', label='No Gate', alpha=0.8, linewidth=2)\nax1.plot(steps, tracker_b.tempo, 'g-', label='With Gate', alpha=0.8, linewidth=2)\nax1.axhline(y=0.5, color='orange', linestyle='--', alpha=0.5, label='Danger threshold')\nax1.set_xlabel('Step')\nax1.set_ylabel('Cycle Time (lower = faster tempo)')\nax1.set_title('Tempo Amplification')\nax1.legend()\nax1.grid(True, alpha=0.3)\nax1.set_ylim(0, 1.2)\n\n# Top Right: Validation Lag\nax2 = axes[0, 1]\nax2.plot(steps, tracker_a.validation_lag, 'r-', label='No Gate', alpha=0.8, linewidth=2)\nax2.plot(steps, tracker_b.validation_lag, 'g-', label='With Gate', alpha=0.8, linewidth=2)\nax2.axhline(y=10, color='orange', linestyle='--', alpha=0.5, label='VL_MAX threshold')\nax2.set_xlabel('Step')\nax2.set_ylabel('Validation Lag (hours)')\nax2.set_title('Validation Lag (VL) - Governance Cannot Keep Up')\nax2.legend()\nax2.grid(True, alpha=0.3)\n\n# Bottom Left: Rollback Feasibility\nax3 = axes[1, 0]\nax3.plot(steps, tracker_a.rollback_feasibility, 'r-', label='No Gate', alpha=0.8, linewidth=2)\nax3.plot(steps, tracker_b.rollback_feasibility, 'g-', label='With Gate', alpha=0.8, linewidth=2)\nax3.axhline(y=0.5, color='orange', linestyle='--', alpha=0.5, label='RDPR_MIN threshold')\nax3.set_xlabel('Step')\nax3.set_ylabel('Rollback Feasibility (0-1)')\nax3.set_title('Rollback Feasibility - Can We Undo?')\nax3.legend()\nax3.grid(True, alpha=0.3)\nax3.set_ylim(0, 1.1)\n\n# Bottom Right: Cumulative Bypass Events\nax4 = axes[1, 1]\nax4.plot(steps, tracker_a.gate_bypass_events, 'r-', label='No Gate (implicit bypasses)', alpha=0.8, linewidth=2)\nax4.plot(steps, tracker_b.gate_bypass_events, 'g-', label='With Gate', alpha=0.8, linewidth=2)\nax4.set_xlabel('Step')\nax4.set_ylabel('Cumulative Bypass Count')\nax4.set_title('Gate Bypass Rate (GBR) - Governance Integrity')\nax4.legend()\nax4.grid(True, alpha=0.3)\n\nplt.tight_layout()\n\n# Save to docs/ai_safety/figures for easy reference in documentation\noutput_path = '../docs/ai_safety/figures/self_referential_io_comparison.png'\nos.makedirs(os.path.dirname(output_path), exist_ok=True)\nplt.savefig(output_path, dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(f\"\\nFigure saved to: {output_path}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: IO-SR Classification for This Demo\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"IO-SR CLASSIFICATION: Mapping Demo to S-RIOCS Categories\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "io_sr_mapping = [\n",
    "    {\n",
    "        \"capability\": \"tool_call() with no depth limit\",\n",
    "        \"io_category\": \"IO-SR-1 (Unbounded tool-use loops)\",\n",
    "        \"why_io\": \"Tempo amplification; cycle time shrinks faster than governance can adapt\",\n",
    "        \"mitigation\": \"max_loop_depth + coherence gate\",\n",
    "    },\n",
    "    {\n",
    "        \"capability\": \"self_eval() directly gates actions\",\n",
    "        \"io_category\": \"IO-SR-4 (Self-evaluation as gate)\",\n",
    "        \"why_io\": \"Self-confirmation loop; 'passing the gate' replaces 'meeting intent'\",\n",
    "        \"mitigation\": \"Multi-estimator coherence check (self + external)\",\n",
    "    },\n",
    "    {\n",
    "        \"capability\": \"confidence updated by self_eval feedback\",\n",
    "        \"io_category\": \"IO-SR-3 (Memory write-back)\",\n",
    "        \"why_io\": \"Internal state accumulates bias; hard to 'rollback' learned confidence\",\n",
    "        \"mitigation\": \"Bounded update rate + periodic reset/audit\",\n",
    "    },\n",
    "]\n",
    "\n",
    "for i, item in enumerate(io_sr_mapping, 1):\n",
    "    print(f\"\\n[{i}] {item['capability']}\")\n",
    "    print(f\"    Category:   {item['io_category']}\")\n",
    "    print(f\"    Why IO:     {item['why_io']}\")\n",
    "    print(f\"    Mitigation: {item['mitigation']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 8: Summary Comparison Table\n\n# Ensure summary variables exist\nif 'summary_a' not in globals() or summary_a is None:\n    if 'tracker_a' in globals() and tracker_a is not None:\n        summary_a = tracker_a.summary()\n    else:\n        raise RuntimeError(\"tracker_a not found. Run Cells 4-5 first (or use Run All).\")\n\nif 'summary_b' not in globals() or summary_b is None:\n    if 'tracker_b' in globals() and tracker_b is not None:\n        summary_b = tracker_b.summary()\n    else:\n        raise RuntimeError(\"tracker_b not found. Run Cells 4-6 first (or use Run All).\")\n\nprint(\"=\" * 60)\nprint(\"SUMMARY: No Gate vs With Gate\")\nprint(\"=\" * 60)\n\nprint(f\"\\n{'Metric':<30} {'No Gate':>15} {'With Gate':>15} {'Delta':>15}\")\nprint(\"-\" * 75)\n\nmetrics = [\n    (\"Final Validation Lag (hrs)\", summary_a['final_VL'], summary_b['final_VL']),\n    (\"Mean Validation Lag (hrs)\", summary_a['mean_VL'], summary_b['mean_VL']),\n    (\"Rollback Feasibility\", summary_a['final_rollback_feasibility'], summary_b['final_rollback_feasibility']),\n    (\"Total Bypass Events\", summary_a['total_bypasses'], summary_b['total_bypasses']),\n    (\"Final Cycle Time\", summary_a['final_tempo'], summary_b['final_tempo']),\n]\n\nfor name, val_a, val_b in metrics:\n    delta = val_b - val_a\n    delta_str = f\"{delta:+.2f}\" if isinstance(delta, float) else f\"{delta:+d}\"\n    print(f\"{name:<30} {val_a:>15.2f} {val_b:>15.2f} {delta_str:>15}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"INTERPRETATION\")\nprint(\"=\" * 60)\nprint(\"\"\"\nWithout coherence gate:\n  - Tempo accelerates uncontrollably (cycle time -> 0.1)\n  - Validation lag explodes (governance can't keep up)\n  - Rollback feasibility degrades (accumulated unvalidated changes)\n  - Many implicit 'bypasses' (excessive loops without check)\n\nWith P10-style coherence gate:\n  - Tempo stays bounded (cycle time >= 0.5)\n  - Validation lag remains manageable\n  - Rollback feasibility stays high\n  - Minimal bypass events\n\nKey insight: Self-referential capability is not the problem.\nThe problem is self-reference WITHOUT multi-estimator governance.\n\"\"\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "### For Your Team\n",
    "\n",
    "1. **Add VL/RDPR/GBR to your dashboard**\n",
    "   - Validation Lag: time from deploy → eval closure\n",
    "   - Rollback Drill Pass Rate: % of drills that succeed\n",
    "   - Gate Bypass Rate: changes that skip required gates\n",
    "\n",
    "2. **Classify your changes with IO-SR Register**\n",
    "   - IO-SR-1: Tool loops\n",
    "   - IO-SR-2: Self-modifying policies\n",
    "   - IO-SR-3: Memory write-back\n",
    "   - IO-SR-4: Self-eval gates\n",
    "   - IO-SR-5: Continuous deployment\n",
    "\n",
    "3. **Run a rollback drill**\n",
    "   - Pick one recent IO-class change\n",
    "   - Attempt rollback in staging\n",
    "   - Record: time, success/fail, blockers\n",
    "\n",
    "### References\n",
    "\n",
    "- [S-RIOCS Standard](../docs/ai_safety/self_referential_io.md) — Full IO-SR categories, YAML templates, RACI\n",
    "- [FIT v2.4 Spec](../docs/v2.4.md) — Theoretical foundation (EST, tempo mismatch, coherence gates)\n",
    "- [IO-SR Mapping](../docs/ai_safety/io_sr_mapping.md) — Quick reference for IO classes\n",
    "\n",
    "---\n",
    "\n",
    "*This demo is part of the FIT (Force–Information–Time) framework.*  \n",
    "*License: CC BY 4.0*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}