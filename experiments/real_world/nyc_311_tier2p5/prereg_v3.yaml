# FIT Tier-2.5 preregistration (NYC 311) - v3
# Purpose: a narrow real-world bridge demo for tempo mismatch and backlog drift.
#
# v3 change (motivated by RUN001 and reviewer feedback):
# - Keep the v2 "window-normalized" rho definition (decision-facing thresholds).
# - Clarify the decision procedure and make it harder to over-interpret:
#   * We designate one PRIMARY run config (W=14, H=14) for interpretation.
#   * Other (W,H) combinations are treated as sensitivity checks (reported, not gated).
# - Require a run-level diagnostics artifact in each output folder to make the
#   EST label auditable without re-running anything.
#
# IMPORTANT: This is a "Tier-2.5 preregistered demonstration" (real-world logs),
# not a claim of universal laws.

preregistration:
  id: "T2p5-NYC311-003"
  title: "NYC 311: window-normalized tempo mismatch and backlog drift (v3, primary config)"
  locked_date: "2026-01-04"
  author: "Qien Huang"
  license: "CC BY 4.0"
  repo: "https://github.com/qienhuang/F-I-T"
  supersedes:
    - "prereg.yaml"
    - "prereg_v2.yaml"

scope:
  dataset: "NYC 311 Service Requests (NYC Open Data)"
  purpose: "Tier-2.5 bridge demo (real-world logs), not a universality claim"
  boundary_policy:
    - "Single agency OR a small agency set (<=3)"
    - "Top-K complaint types (K <= 10) within the chosen agency boundary"
    - "Fixed created-date range (declare before running)"
  exclusions:
    - "Rows without created timestamp"
    - "Rows with negative (closed - created) lag"
  caveats:
    - "VL/RDPR/GBR are conservative governance proxies, not incident predictors."
    - "If the coherence gate fails, treat results as ESTIMATOR_UNSTABLE (measurement problem, not theory win/lose)."
    - "This prereg uses a created-date boundary; closures may extend beyond the created-date end, which creates a natural 'tail' period. Plots should mark created_end explicitly."

estimator_tuple:
  # E = (S_t, B, C_hat, F_hat, I_hat, W)
  S_t:
    description: "Daily aggregated operational state"
    fields:
      - "A_t: arrivals per day (created_date)"
      - "C_t: closures per day (closed_date)"
      - "B_t: backlog (cumulative sum of A_t - C_t)"
      - "VL_t: median close lag (days) for closure events on day t (may be missing on low-closure days)"
  B:
    description: "Boundary (must be fixed before running)"
    fields:
      - "created_date_range: [start_date, end_date]"
      - "agency_filter: [AGENCY_1, ...]"
      - "complaint_type_filter: top_K_types (computed within the agency boundary)"
      - "time_unit: day"
  C_hat:
    name: "backlog_and_forward_drift"
    primary: "B_t (backlog level)"
    secondary: "drift_norm(t; H) = (B_{t+H} - B_t) / sum_{i=t..t+H} A_i"
  F_hat:
    name: "demand_pressure_proxy"
    primary: "A_t (arrivals)"
  I_hat:
    name: "not_used_in_v3_demo"
    note: "Reserved for future extensions (e.g., complaint-type entropy); not used in H1 test."

tempo_mismatch:
  rho_mode: "window_normalized"
  definitions:
    tau_g:
      description: "Governance latency proxy (median close lag)"
      estimator: "tau_g(t) = VL_t (days)"
    rho:
      description: "Mismatch ratio (window-normalized)"
      estimator: "rho(t) = median_W(tau_g) / W"
  thresholds:
    rho_yellow: 1.0
    rho_red: 3.0

primary_run:
  # Primary configuration for interpretation (narrow and stable).
  # Any additional runs MUST be reported, but do not change the primary label.
  W: 14
  H: 14

sensitivity_runs:
  # Optional / diagnostic only. Report if run.
  candidates:
    - {W: 7, H: 7}
    - {W: 7, H: 14}
    - {W: 14, H: 7}

preregistered_parameters:
  delta_drift_min: 0.05
  n_event_min: 10
  coherence_rho_min: 0.2

data_integrity_checks:
  required_tool: "scripts/sanity_check_311_boundary.py"
  must_pass:
    - id: "NO_IMPOSSIBLE_ZERO_RUN"
      description: "Within the created-date window, the longest consecutive zero-arrival run should be small; otherwise treat as export/filtering artifact."
      threshold_days: 7
      action_on_fail: "DATA_INTEGRITY_ISSUE"
    - id: "NONTRIVIAL_SAMPLE"
      description: "Enough events to make medians meaningful inside the boundary."
      min_rows_in_window: 1000
      action_on_fail: "INCONCLUSIVE"

hypotheses:
  H1:
    statement: "Sustained window-normalized tempo mismatch is associated with positive forward backlog drift."
    operational_test:
      event_definition: "event(t) = [rho(t) > rho_yellow] for a full W-day window (sustained mismatch)"
      outcome: "drift_norm(t; H)"
      effect_size:
        delta: "median(drift_norm | event) - median(drift_norm | non_event)"
        support_if:
          - "n_event >= n_event_min"
          - "median(drift_norm | event) > 0"
          - "delta >= delta_drift_min"
        challenge_if:
          - "n_event >= n_event_min"
          - "delta <= 0 OR median(drift_norm | event) <= 0"
        inconclusive_if:
          - "n_event < n_event_min"
  H0:
    statement: "No stable association under the prereg boundary."

coherence_gate:
  # P10-like check (lightweight): if C_hat derivatives and C_hat forward drift disagree too much,
  # mark ESTIMATOR_UNSTABLE and do not interpret H1.
  #
  # Metric is computed by scripts/compute_311_metrics.py and exported to run_diagnostics.*
  P10_like:
    metric: "spearman(dB_t, drift_norm(t;H)) over paired days"
    thresholds:
      rho_min: 0.2
    rule:
      - "Evaluate ONLY on the PRIMARY (W,H) run."
      - "If rho_spearman is None OR abs(rho_spearman) < rho_min, label ESTIMATOR_UNSTABLE."
    interpretation:
      - "If ESTIMATOR_UNSTABLE, do not interpret H1 as supported/challenged under this estimator setup."

reporting:
  must_include:
    - "Prereg version: prereg_v3.yaml"
    - "Exact boundary (created-date range, agencies, complaint types)"
    - "Boundary sanity report output (from scripts/sanity_check_311_boundary.py) for the declared created-date window"
    - "Primary run outputs (W=14,H=14): metrics_daily.csv + overview.* + run_diagnostics.*"
    - "If sensitivity runs are executed: report all of them (no cherry-picking)"
    - "Event counts: n_event, n_non_event (after dropping undefined drift_norm)"
    - "Effect size delta and medians for event/non-event"
    - "Coherence gate status + rho_spearman (and sign)"
    - "Negative results and boundary cases"
  outputs:
    - "metrics_daily.csv"
    - "overview.svg"
    - "overview.png (optional)"
    - "run_diagnostics.json"
    - "run_diagnostics.md"

failure_statement_template:
  text:
    - "Prereg: prereg_v3.yaml"
    - "Boundary: created_date=[start_date, end_date], agency=[...], top_K_types=..."
    - "Primary run: W=14, H=14"
    - "Counts: n_event=..., n_non_event=... (after filtering undefined drift_norm)"
    - "Effect: median_event=..., median_non_event=..., delta=... (delta_drift_min=0.05)"
    - "Coherence: status=..., rho_spearman=..., sign=... (rho_min=0.2)"
    - "Conclusion label: supported | challenged | inconclusive | estimator_unstable"
