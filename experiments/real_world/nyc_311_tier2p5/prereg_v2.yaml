# FIT Tier-2.5 preregistration (NYC 311) - v2
# Purpose: a narrow real-world bridge demo for tempo mismatch and backlog drift.
#
# v2 change (motivated by RUN001 results):
# - The v1 definition of update tempo as tau_u(t)=1/max(A_t,1) makes rho scale with daily
#   arrival volume, producing rho >> 1 almost everywhere for high-volume agencies (HPD),
#   which collapses the "rho > 1" event into a near-constant and breaks the intended
#   threshold test in H1.
# - v2 keeps the same boundary discipline and H1 structure, but redefines rho as a
#   window-normalized governance delay: rho(t)=median_W(VL_t)/W, so rho=1 corresponds to
#   "median close lag ~= one governance window".
#
# IMPORTANT: This is a "Tier-2.5 preregistered demonstration" (real-world logs),
# not a claim of universal laws.

preregistration:
  id: "T2p5-NYC311-002"
  title: "NYC 311: window-normalized tempo mismatch and backlog drift (v2)"
  locked_date: "2026-01-04"
  author: "Qien Huang"
  license: "CC BY 4.0"
  repo: "https://github.com/qienhuang/F-I-T"
  supersedes: "prereg.yaml"

scope:
  dataset: "NYC 311 Service Requests (NYC Open Data)"
  purpose: "Tier-2.5 bridge demo (real-world logs), not a universality claim"
  boundary_policy:
    - "Single agency OR a small agency set (<=3)"
    - "Top-K complaint types (K <= 10) within the chosen agency boundary"
    - "Fixed created-date range (declare before running)"
  exclusions:
    - "Rows without created timestamp"
    - "Rows with negative (closed - created) lag"
  caveats:
    - "VL/RDPR/GBR are conservative governance proxies, not incident predictors."
    - "If coherence gate fails, treat results as estimator-unstable (not a theory win/lose)."
    - "This prereg uses a created-date boundary; closures may extend beyond the created-date end, which creates a natural 'tail' period. Plots should mark the created_end boundary explicitly."

estimator_tuple:
  # E = (S_t, B, C_hat, F_hat, I_hat, W)
  S_t:
    description: "Daily aggregated operational state"
    fields:
      - "A_t: arrivals per day (created_date)"
      - "C_t: closures per day (closed_date)"
      - "B_t: backlog (cumulative sum of A_t - C_t)"
      - "VL_t: median close lag (days) for closure events on day t (may be missing on low-closure days)"
  B:
    description: "Boundary (must be fixed before running)"
    fields:
      - "created_date_range: [start_date, end_date]"
      - "agency_filter: [AGENCY_1, ...]"
      - "complaint_type_filter: top_K_types (computed within the agency boundary)"
      - "time_unit: day"
  C_hat:
    name: "backlog_and_forward_drift"
    primary: "B_t (backlog level)"
    secondary: "drift_norm(t; H) = (B_{t+H} - B_t) / sum_{i=t..t+H} A_i"
  F_hat:
    name: "demand_pressure_proxy"
    primary: "A_t (arrivals)"
  I_hat:
    name: "not_used_in_v2_demo"
    note: "Reserved for future extensions (e.g., complaint-type entropy); not used in H1 test."
  W:
    description: "Governance/evaluation window (days) - also used as the rho normalization constant"
    candidates: [7, 14]
  H:
    description: "Forward horizon for drift_norm (days)"
    candidates: [7, 14]

tempo_mismatch:
  rho_mode: "window_normalized"
  definitions:
    tau_g:
      description: "Governance latency proxy (median close lag)"
      estimator: "tau_g(t) = VL_t (days)"
    rho:
      description: "Mismatch ratio (window-normalized)"
      estimator: "rho(t) = median_W(tau_g) / W"
  implementation_notes:
    - "median_W(tau_g) requires at least ceil(W/2) valid days."
    - "rho uses W as a normalization constant; rho=1 means median close lag equals one W-day window."
  thresholds:
    rho_yellow: 1.0
    rho_red: 3.0

preregistered_parameters:
  # Effect-size and minimum sample requirements to avoid 'explain everything' post-hoc moves.
  delta_drift_min: 0.05
  n_event_min: 10
  coherence_rho_min: 0.2

hypotheses:
  H1:
    statement: "Sustained window-normalized tempo mismatch is associated with positive forward backlog drift."
    operational_test:
      event_definition: "event(t) = [rho(t) > rho_yellow] for a full W-day window (sustained mismatch)"
      outcome: "drift_norm(t; H)"
      effect_size:
        delta: "median(drift_norm | event) - median(drift_norm | non_event)"
        support_if:
          - "n_event >= n_event_min"
          - "median(drift_norm | event) > 0"
          - "delta >= delta_drift_min"
        challenge_if:
          - "n_event >= n_event_min"
          - "delta <= 0 OR median(drift_norm | event) <= 0"
        inconclusive_if:
          - "n_event < n_event_min"
  H0:
    statement: "No stable association under the prereg boundary; or direction flips once coherence is enforced."

coherence_gate:
  # Minimal P10-style check: if primary and secondary C_hat disagree wildly, flag estimator instability.
  # Operationalization (matches script):
  #   dB_t = B_t - B_{t-1}
  #   rho_s = Spearman(dB_t, drift_norm(t; H)) over paired days
  P10_like:
    requirement: "Backlog changes (dB_t) and forward drift_norm should be directionally coherent."
    thresholds:
      rho_min: 0.2
    rule:
      - "Compute rho_spearman for each (W,H) run."
      - "If rho_spearman is None OR abs(rho_spearman) < rho_min, mark estimator_unstable."
      - "If multiple (W,H) runs are executed and corr_sign differs across runs, mark estimator_unstable."
    status_labels:
      - "supported"
      - "challenged"
      - "estimator_unstable"
    interpretation:
      - "If estimator_unstable, do not interpret H1 as supported/challenged; report as measurement instability."

reporting:
  must_include:
    - "Prereg version: prereg_v2.yaml"
    - "Exact boundary (created-date range, agencies, complaint types)"
    - "Chosen W and H (and the prereg list of candidates); if multiple runs, report all (W,H) results"
    - "Event counts: n_event, n_non_event (after dropping undefined drift_norm)"
    - "Effect size delta and medians for event/non-event"
    - "Coherence gate status + rho_spearman (and sign)"
    - "All plots + metrics CSV export"
    - "Negative results and boundary cases"
    - "A note clarifying the created-date boundary and the closure tail (if any), to avoid post-hoc '2025 regime change' narratives."
  outputs:
    - "metrics_daily.csv"
    - "overview.svg"
    - "overview.png (optional)"
    - "decision_view.png (optional, for decision-makers)"

failure_statement_template:
  # Copy/paste into reports/issues when results are negative or inconclusive.
  text:
    - "Prereg: prereg_v2.yaml"
    - "Boundary: created_date=[start_date, end_date], agency=[...], top_K_types=..."
    - "Run(s): W=..., H=... (candidates: W=[7,14], H=[7,14])"
    - "Counts: n_event=..., n_non_event=... (after filtering undefined drift_norm)"
    - "Effect: median_event=..., median_non_event=..., delta=... (delta_drift_min=0.05)"
    - "Coherence: status=..., rho_spearman=..., sign=... (rho_min=0.2)"
    - "Conclusion label: supported | challenged | inconclusive | estimator_unstable"
