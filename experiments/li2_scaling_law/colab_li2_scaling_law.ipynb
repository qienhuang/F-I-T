{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "colab_li2_scaling_law.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Li2 Grokking: Densify/Beta-only Colab Notebook\n",
        "\n",
        "This notebook is for the **densify + beta / beta_delay** follow-up only.\n",
        "It is meant for cloud runtimes that reset frequently (Colab), so it always updates the repo checkout.\n",
        "\n",
        "What it does:\n",
        "- Runs a multi-seed densified ratio grid (resumable) via `multiseed_fill.py`\n",
        "- Computes `beta` from `grok_epoch` via `analyze_beta_transition.py`\n",
        "- Computes `beta_delay` from `grok_delay` via `analyze_grok_speed.py --use_delay --max_delta_r ...`\n",
        "\n",
        "Notes:\n",
        "- This is compute-heavy (many training runs). Start with **one M** if you want a fast check.\n",
        "- Outputs are written under `experiments/li2_scaling_law/results/`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) Configure repo URL\n",
        "\n",
        "Set your GitHub repo URL (or a fork) and branch.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "REPO_URL = \"https://github.com/<OWNER>/<REPO>.git\"  # TODO: replace\n",
        "BRANCH = \"main\"\n",
        "\n",
        "REPO_DIR = \"F-I-T\"\n",
        "EXPERIMENT_DIR = f\"{REPO_DIR}/experiments/li2_scaling_law\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Setup environment\n",
        "\n",
        "Colab usually has PyTorch. We install lightweight deps used by analysis/plotting.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "!python -V\n",
        "!pip -q install numpy matplotlib tqdm pyyaml\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "try:\n",
        "    import torch  # noqa: F401\n",
        "except Exception:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"torch\"])\n",
        "    import torch  # noqa: F401\n",
        "\n",
        "print('torch', torch.__version__, 'cuda?', torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Clone/update repo\n",
        "\n",
        "If the repo already exists, this cell will update it to the latest `BRANCH`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import subprocess\n",
        "\n",
        "if REPO_URL.startswith('https://github.com/<OWNER>'):\n",
        "    raise SystemExit('Please set REPO_URL to your repo (or a fork) first.')\n",
        "\n",
        "repo_path = Path(REPO_DIR)\n",
        "if not repo_path.exists():\n",
        "    subprocess.check_call(['git', 'clone', '--depth', '1', '--branch', BRANCH, REPO_URL, REPO_DIR])\n",
        "else:\n",
        "    print('Repo already exists:', REPO_DIR)\n",
        "    subprocess.check_call(['git', '-C', REPO_DIR, 'fetch', 'origin', BRANCH])\n",
        "    subprocess.check_call(['git', '-C', REPO_DIR, 'checkout', BRANCH])\n",
        "    subprocess.check_call(['git', '-C', REPO_DIR, 'pull', '--ff-only'])\n",
        "\n",
        "assert Path(EXPERIMENT_DIR).exists(), f\"Missing {EXPERIMENT_DIR}\"\n",
        "%cd {EXPERIMENT_DIR}\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Sanity check: prevent running an outdated checkout\n",
        "from pathlib import Path\n",
        "import subprocess\n",
        "\n",
        "required = [\n",
        "    'train.py',\n",
        "    'multiseed_fill.py',\n",
        "    'analyze_beta_transition.py',\n",
        "    'analyze_grok_speed.py',\n",
        "]\n",
        "missing = [p for p in required if not Path(p).exists()]\n",
        "if missing:\n",
        "    raise SystemExit('Missing required files (repo checkout likely outdated): ' + ', '.join(missing))\n",
        "\n",
        "head = subprocess.check_output(['git', '-C', REPO_DIR, 'rev-parse', '--short', 'HEAD']).decode().strip()\n",
        "print('Git HEAD:', head)\n",
        "print('analyze_grok_speed has --max_delta_r?', '--max_delta_r' in Path('analyze_grok_speed.py').read_text(encoding='utf-8', errors='replace'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Densify + beta / beta_delay (multi-seed)\n",
        "\n",
        "Edit `SPEC` to control which M values and ratios you run.\n",
        "\n",
        "Default spec densifies around previously observed boundaries:\n",
        "- M=23: r_crit ~ 0.575\n",
        "- M=41: r_crit ~ 0.490\n",
        "- M=59: r_crit ~ 0.450\n",
        "\n",
        "Tip: start with a single M (e.g., only `59:...`) if you want a fast run.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "OUT_DIR = \"results/beta_multiseed_colab_v2\"\n",
        "SEEDS = \"42,123,456\"\n",
        "\n",
        "# At least 1 below-boundary + 5+ above-boundary points per M.\n",
        "# You can remove M blocks to reduce compute.\n",
        "SPEC = (\n",
        "    \"23:0.56,0.58,0.59,0.60,0.61,0.62;\"\n",
        "    \"41:0.48,0.50,0.51,0.52,0.53,0.54;\"\n",
        "    \"59:0.44,0.46,0.47,0.48,0.49,0.50\"\n",
        ")\n",
        "\n",
        "!python multiseed_fill.py --spec \"{SPEC}\" --seeds {SEEDS} --output_dir {OUT_DIR}\n",
        "\n",
        "!python analyze_beta_transition.py --results_dir {OUT_DIR} --output_dir {OUT_DIR}/analysis_beta --min_prob 1.0 --min_points 5\n",
        "\n",
        "# beta_delay (near-boundary cap)\n",
        "!python analyze_grok_speed.py --results_dir {OUT_DIR} --output_dir {OUT_DIR}/analysis_delay_near --min_prob 1.0 --min_points 3 --use_delay --max_delta_r 0.07\n",
        "\n",
        "!ls -la {OUT_DIR}/analysis_beta || true\n",
        "!ls -la {OUT_DIR}/analysis_delay_near || true\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Download artifacts\n",
        "\n",
        "Zip the `results/` directory and download.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "zip_path = Path('li2_results_colab.zip')\n",
        "if zip_path.exists():\n",
        "    zip_path.unlink()\n",
        "\n",
        "shutil.make_archive(zip_path.with_suffix(''), 'zip', root_dir='.', base_dir='results')\n",
        "print('Wrote', zip_path)\n",
        "\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(str(zip_path))\n",
        "except Exception as e:\n",
        "    print('Download helper not available:', e)\n"
      ]
    }
  ]
}

