》# FIT Framework v2.2

*A Minimal Axiomatic Framework for Evolutionary Dynamics Across Substrates* 

---

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.18039307.svg)](https://doi.org/10.5281/zenodo.18039307) 
[![License: CC BY 4.0](https://img.shields.io/badge/License-CC_BY_4.0-lightgrey.svg)](https://creativecommons.org/licenses/by/4.0/)  
**Author**: Qien Huang (qienhuang@hotmail.com)  
**License**: CC-BY-4.0  
**Repository**: [https://github.com/qienhuang/F-I-T](https://github.com/qienhuang/F-I-T)  
**ORCID**: https://orcid.org/0009-0003-7731-4294

---

## Abstract

We propose the Force–Information–Time (FIT) Framework, an axiomatic approach to unifying evolutionary dynamics across physical, biological, cognitive, and social systems. Building on five primitive concepts—Force, Information, Time, Constraint, and State—we articulate six working laws governing system evolution and establish a dependency chain that makes explicit which laws follow almost tautologically from the primitives and basic information theory, and which require additional modelling assumptions (e.g., closedness, coarse-graining, near‑equilibrium behavior).

The framework generates 18 falsifiable propositions spanning thermodynamics, information theory, and complexity science, with explicit validation pathways through computational models (Conway’s Game of Life, Langton’s Ant), theoretical analysis, and empirical data. Unlike existing frameworks that address isolated aspects of evolution (e.g., Free Energy Principle for perception, Constructor Theory for transformations), FIT provides a minimal axiomatic foundation from which diverse evolutionary phenomena can be organized as special cases. We clarify the distinction between entropy  $ H $  and information gain  $ I_{\text{gain}} $ , and introduce a scalar notion of constraint  $ C(t) $  that makes precise how accessible state space shrinks over time.

We show how the framework reframes apparent paradoxes in evolutionary endpoints, particularly concerning “nirvana states” characterized (for a given coarse‑graining) by high constraint and low force variance. We discuss immediate applications to AI safety (controlled optimization termination), institutional design (stability–adaptivity trade‑offs), and complexity science (phase transition prediction). All propositions are computationally testable, and we provide a prioritized validation roadmap beginning with cellular automata verification. The primary aim of this paper is to establish axiomatic coherence and falsifiable structure; FIT is offered as a candidate universal language for evolutionary processes, not as a dogma.

**Keywords**: evolutionary dynamics, axiomatic framework, information theory, complexity, nirvana states, AI safety

---

## 1. Introduction

### 1.1 The Fragmentation Problem

Modern science confronts evolutionary phenomena through fragmented lenses: thermodynamics describes energy dissipation, information theory quantifies uncertainty reduction, complexity science studies emergent order, and evolutionary biology tracks adaptation. While each framework succeeds within its domain, their mutual inconsistency impedes cross‑disciplinary synthesis. Consider three illustrative tensions:

1. **Thermodynamic–informational tension**
   The Second Law mandates entropy increase, yet biological and cognitive systems systematically reduce local entropy through information processing. Existing reconciliations (e.g., Landauer’s principle) are powerful but tied to computation‑specific setups and do not generalize cleanly to all evolutionary phenomena.

2. **Optimization endpoint ambiguity**
   Gradient‑following systems in AI and nature face the “what comes after convergence?” question. Does evolution terminate at local optima, continue indefinitely, or transition to qualitatively different dynamics? Current frameworks (e.g., evolutionary game theory) describe convergence but not post‑convergence regimes or “frozen” states in a unified way.

3. **Scale‑dependent laws**
   The same system exhibits different apparent evolutionary laws at micro (molecular), meso (organismal), and macro (ecological or social) scales. We lack a common language to describe when and how laws transform across scales and why certain patterns (e.g., criticality, phase transitions) recur.

These are not mere technical gaps. They signal the absence of **shared axioms** that underlie all these domains. Just as Maxwell’s equations unified electricity and magnetism by revealing their common electromagnetic foundation, we seek axioms that expose the deep structure shared by all evolutionary processes.

### 1.2 Existing Frameworks: Achievements and Limitations

Several ambitious frameworks attempt partial unification:

* **Free Energy Principle (FEP)**: Self‑organizing systems minimize variational free energy, unifying perception, learning, and action. Powerful for neural and cognitive systems, but its dependence on Markov blankets and near‑equilibrium assumptions limits applicability to many far‑from‑equilibrium or non‑agentic systems.

* **Constructor Theory**: Reformulates physics in terms of possible/impossible transformations. It offers a principled language for constraints and counterfactuals, but remains largely atemporal and lacks quantitative dynamics for intermediate evolutionary stages.

* **Adami‑style physical complexity**: Defines complexity as information about the environment stored in genomes. This is operationally attractive for biological evolution, but does not extend seamlessly to non‑genetic systems (e.g., markets, artificial learning systems) without forcing analogies.

* **Computational universe approaches (e.g., Wolfram)**: Propose that all systems are computational processes governed by simple rules. They catalog rich phenomenology (especially via cellular automata), but do not provide a principled method to derive or select rules from first principles.

Each framework provides valuable insight but assumes specific ontological commitments (Markov blankets, constructors, genomes, computations). **FIT takes a different route**: it asks

> What is the minimal set of primitives required to talk about *any* evolutionary process, regardless of substrate?

and then investigates what laws follow from those primitives plus basic information theory.

### 1.3 The FIT Approach: Axiomatic Minimalism (v2.2)

The Force–Information–Time (FIT) Framework rests on five primitives chosen for their unavoidability:

* **Force (F)**
  Directed influence causing state change. Generalizes physical force, selection pressure, incentive and reward gradients, etc.

* **Information / Entropy (I, H)**
  Measured distinctions over the state space. In practice we use Shannon entropy  $ H(S) $  to quantify uncertainty and information gains  $ I_{\text{gain}} $  (e.g., reductions in  $ H $  or mutual information) to quantify knowledge acquisition.

* **Time (T)**
  An ordering of events that enables change. We do not assume continuity or reversibility—only that states can be temporally ordered.

* **Constraint (C)**
  Reduction of accessible state space. At the set level, constraints carve out an accessible subset  $ \mathcal{S}_{\text{accessible}}(t) \subseteq \mathcal{S} $ . At the scalar level, we define  $ C(t) $  so that constraints can be compared and differentiated.

* **State (S)**
  System configuration at time  $ t $  (positions, concentrations, neural activations, policy parameters, institutional rules, etc.).

These primitives are **pre‑theoretical**: they do not presuppose particular mechanisms (e.g., natural selection) or substrates (e.g., carbon‑based life). A system lacking any primitive cannot exhibit evolution in the usual sense of “state changes under directed influences over time, within a constrained space”.

From these five primitives, FIT organizes six working laws/principles. In v2.2 we distinguish:

* **Tier 1 laws**
  Laws that follow almost directly from primitive definitions plus standard information‑theoretic results. Once notation is fixed, they are close to tautologies.

* **Tier 2 laws**
  Laws that require additional assumptions about closure, coarse‑graining, and equilibrium‑like regimes. They are powerful working hypotheses, not logical necessities.

We use the following labels (full statements in Section 3):

1. **Law 1 – Force Directionality**
   On a state space with a defined force field  $ F : \mathcal{S} \times T \to \mathbb{R}^n $ , the instantaneous direction of state change aligns with  $ F(S,t) $  itself (or  $ -\nabla V(S,t) $  when a potential  $ V $  exists):

   $$
   \frac{dS}{dt} = \alpha F(S,t)
   \quad \text{or} \quad
   \frac{dS}{dt} = -\alpha \nabla V(S,t)
   $$

2. **Law 2 – Information Capacity Bound Under Constraints**
   Given a finite reference state space  $ \mathcal{S} $  and an accessible subset  $ \mathcal{S}_{\text{accessible}}(t) $  determined by constraints at time  $ t $ , the Shannon entropy obeys

   $$
   0 \le H(S_t) \le \log \big|\mathcal{S}_{\text{accessible}}(t)\big|
   $$

   Defining a scalar constraint measure

   $$
   C(t) := \log|\mathcal{S}| - \log\big|\mathcal{S}_{\text{accessible}}(t)\big|
   $$

   we obtain an entropy upper bound and an upper bound on information gain:

   $$
   H(S_t) \le \log|\mathcal{S}| - C(t)
   $$

   $$
   I_{\text{gain}}(0 \to t) = H(S_0) - H(S_t) \le C(t) - C(0)
   $$

3. **Law 3 – Time Asymmetry of Force Application**
   At a given coarse‑graining and constraint structure, forces map present to future states,

   $$
   S(t+\Delta t) = \Phi[S(t), F(t)]
   $$

   but the mapping is generally many‑to‑one. Forward dynamics are well‑defined; backward reconstruction is generically ill‑posed.

These are **Tier 1**: they rest only on primitives and standard information theory.

4. **Law 4 – Constraint Accumulation (under equilibrium approach)**
   In sufficiently closed systems, under a fixed coarse‑graining and in regimes where the system approaches a statistical equilibrium, the scalar constraint measure  $ C(t) $  is non‑decreasing on long time scales (allowing for small local fluctuations):

   $$
   C(t+\Delta t) \ge C(t) - \varepsilon(t), \quad \varepsilon(t) \to 0 \text{ as } t \to \infty
   $$

5. **Law 5 – Equilibrium Nirvana Condition (for frozen attractors)**
   For systems whose coarse‑grained dynamics converge to *frozen* attractors (no appreciable change at the observation scale), the variance of the net force field at that scale tends to zero as constraints saturate:

   $$
   \sigma^2(F) \to 0
   \quad \text{as} \quad
   C(t) \to C_{\max}
   $$

6. **Law 6 – Equilibrium Information Efficiency Hypothesis (provisional)**
   In certain highly adapted system classes (e.g., coding schemes, regulatory architectures), near such frozen nirvana states the ratio of “useful information”  $ I_{\text{useful}}(t) $  to constraint  $ C(t) $  approaches a class‑specific constant  $ k $ :

   $$
   \lim_{C(t) \to C_{\max}} \frac{I_{\text{useful}}(t)}{C(t)} = k
   $$

   Here  $ I_{\text{useful}} $  is an operationally defined information measure (e.g., predictive information about relevant environment variables).

Law 4–6 are **Tier 2**. They hold under explicit additional assumptions and are exactly the kind of statements that should be stress‑tested across domains.

Section 3 restates all six laws precisely and organizes them into a dependency chain. The rest of the paper develops falsifiable propositions and test protocols derived from this structure.

### 1.4 Falsifiability and Validation Strategy

A unifying framework is scientifically valuable only if it can be **falsified**. FIT addresses this by:

1. **Explicit propositions**
   18 concrete predictions (Section 4) testable in computational and physical systems.

2. **Validation matrix**
   A 3×3 grid mapping propositions to test environments (easy/medium/hard) and evidence types (computational/mathematical/empirical).

3. **Prioritized roadmap**
   Beginning with Conway’s Game of Life and Langton’s Ant—systems where ground truth dynamics are fully known.

Example:

> **P1 (Nirvana irreversibility)**: In closed systems where a coarse‑grained nirvana regime is defined by  $ \sigma^2(F) < \varepsilon $ , the probability of spontaneously returning to a high‑variance regime  $ \sigma^2(F) > k\varepsilon $  in a finite time window, without external constraint relaxation, approaches zero as  $ C(t) \to C_{\max} $ .

This is testable in Game of Life still‑lifes and in engineered RL agents. Clear counterexamples would force revision of the framework.

### 1.5 Paper Organization

* **Section 2**: Formal definitions of primitives with mathematical representations
* **Section 3**: Derivation and positioning of six laws and their dependency chain
* **Section 4**: Complete list of 18 falsifiable propositions and detailed analysis of three
* **Section 5**: Validation roadmap with concrete computational protocols
* **Section 6**: Relation to existing frameworks (FEP, Constructor Theory, etc.)
* **Section 7**: Applications to AI safety, institutional design, and complexity science
* **Section 8**: Limitations and future directions
* **Section 9**: Conclusion

Appendix A defines a machine‑readable proposition registry schema.

---

## 2. Axiomatic Foundation: The Five Primitives

### 2.1 Primitive 1: Force (F)

**Informal definition**
Force is any directed influence that tends to change system state.

**Formal definition**

$$
F : \mathcal{S} \times T \to \mathbb{R}^n
$$

where  $ \mathcal{S} $  is the state space,  $ T $  is the time domain, and  $ \mathbb{R}^n $  is the force vector space.

**Key properties**

* **Directionality**:  $ F $  has magnitude and direction in state space.
* **(Typically) locality**: In many models  $ F(s,t) $  depends on a “local neighborhood” of  $ s $ . FIT does not require strict locality, but many testbeds will approximate it.
* **Decomposability**: If multiple influences exist,  $ F_{\text{total}} = \sum_i F_i $ .

**Minimal working example (MWE)** – Chemotaxis in *E. coli*

* State space:  $ \mathcal{S} = \mathbb{R}^3 $  (bacterium position).
* Force:  $ F(x,t) = k \nabla[\text{glucose}](x,t) $ .
* Dynamics: bacteria tend to move along  $ F $ .

This matches Law 1’s form  $ \frac{dS}{dt} = \alpha F(S,t) $  when motion is modeled as drift plus noise.

**Cross‑domain manifestations**

| System type | Force manifestation                       | State space                 |
| ----------- | ----------------------------------------- | --------------------------- |
| Physical    | Newtonian force, EM fields                | Positions, momenta          |
| Chemical    | Reaction affinities                       | Concentrations              |
| Biological  | Fitness gradients, selection pressure     | Genotype/phenotype          |
| Cognitive   | Prediction errors, reward gradients       | Neural activations, beliefs |
| Social      | Incentives, norm pressures                | Agent strategies            |
| Economic    | Profit gradients, arbitrage opportunities | Allocations, prices         |

FIT’s unification arises from recognizing these as structurally similar “vectors in state space”.

---

### 2.2 Primitive 2: Information and Entropy (I, H)  *(v2.2)*

We distinguish explicitly between:

* **Entropy  $ H(S) $** – uncertainty about the system state.
* **Information gain  $ I_{\text{gain}} $** – reduction in uncertainty between a prior and a posterior.

**Entropy (uncertainty)**

Given a probability distribution  $ P_t(s) $  over states  $ s \in \mathcal{S}_{\text{accessible}}(t) $ :

$$
H(S_t) = - \sum_{s \in \mathcal{S}_{\text{accessible}}(t)} P_t(s) \log P_t(s)
$$

Properties:

* $ H(S_t) \ge 0 $ .
* $ H(S_t) \le \log \big|\mathcal{S}_{\text{accessible}}(t)\big| $  (maximum at uniform distribution).
* For independent subsystems,  $ H(S_1, S_2) = H(S_1) + H(S_2) $ .

**Information gain (knowledge)**

Between a prior  $ P_0 $  and posterior  $ P_1 $ :

$$
I_{\text{gain}}(P_0 \to P_1) := H(P_0) - H(P_1)
$$

Whenever  $ P_1 $  is more concentrated than  $ P_0 $ , we have  $ I_{\text{gain}} \ge 0 $ .

**MWE – DNA base encoding**

* State space:  $ \mathcal{S} = {A, T, G, C} $ .

* Prior:  $ P_0(A) = P_0(T) = P_0(G) = P_0(C) = 0.25 $ .

* Entropy:

  $$
  H_0 = -4 \times 0.25 \log_2(0.25) = 2 \text{ bits per base}
  $$

* After observing “A” at position 1:
  Posterior  $ P_1(A)=1 $  (others 0), so  $ H_1 = 0 $  and

  $$
  I_{\text{gain}} = H_0 - H_1 = 2 \text{ bits}
  $$

In FIT, “knowledge stored in a system” is typically represented via suitable  $ I_{\text{gain}} $  or mutual information terms; “raw uncertainty” uses  $ H $ .

**Connection to constraints**

For a finite reference state space  $ \mathcal{S} $ , constraints determine the accessible subset  $ \mathcal{S}_{\text{accessible}}(t) $ . The entropy upper bound at time  $ t $  is

$$
H_{\max}(t) = \log \big|\mathcal{S}_{\text{accessible}}(t)\big|
$$

As constraints accumulate,  $ |\mathcal{S}*{\text{accessible}}(t)| $  shrinks, reducing  $ H*{\max}(t) $  and simultaneously raising the **potential** knowledge  $ I_{\text{gain}} $  (see Law 2).

---

### 2.3 Primitive 3: Time (T)

**Informal definition**
Time provides an ordering of changes.

**Formal representation**

We assume an index set  $ T $  (discrete or continuous) with an order relation  $ < $ . States are indexed as  $ S(t) $ . We do not assume reversibility or a particular metric; only an ordering.

**Key properties**

* **Ordering**: If  $ t_1 < t_2 $ , then  $ S(t_1) $  precedes  $ S(t_2) $ .
* **Discrete or continuous**: Both integer time steps and real‑valued time are allowed.
* **No a priori symmetry**: The arrow of time in FIT comes from dynamics (Law 3), not imposed directly on  $ T $ .

**MWE – Game of Life**

* Time:  $ t \in {0,1,2,\dots} $ .
* Transition:  $ S(t+1) = f(S(t)) $  (deterministic rule).
* Many initial states converge to the same still‑life; forward evolution is unambiguous, backward reconstruction is not.

Time in FIT is thus the index of evolution; causality is expressed through how forces map  $ S(t) $  to  $ S(t+\Delta t) $ .

---

### 2.4 Primitive 4: Constraint (C)  *(v2.2)*

**Informal definition**
Constraints are reductions in accessible state space.

**Set‑valued representation**

$$
C : \mathcal{S} \to 2^{\mathcal{S}}
$$

$$
C(s) = { s' \in \mathcal{S} : s \to s' \text{ is forbidden} }
$$

or, as a map on the entire space:

$$
C(\mathcal{S}) = \mathcal{S}_{\text{accessible}}(t) \subseteq \mathcal{S}
$$

This emphasizes constraints as “forbidden transitions” or “excluded states”.

**Scalar constraint measure  $ C(t) $**

To support Law 2 and subsequent propositions, we define a scalar measure:

$$
C(t) := \log|\mathcal{S}| - \log\big|\mathcal{S}_{\text{accessible}}(t)\big|
$$

Interpretation:

* $ C(t) = 0 $ : unconstrained (all states accessible).
* $ C(t) $  increases as  $ |\mathcal{S}_{\text{accessible}}(t)| $  shrinks.
* Maximum  $ C_{\max} = \log|\mathcal{S}| $  when  $ |\mathcal{S}_{\text{accessible}}(t)| = 1 $  (only one state accessible).

In more general settings, any strictly decreasing function of  $ |\mathcal{S}_{\text{accessible}}(t)| $  could serve; the logarithm is convenient and natural for information‑theoretic interpretations.

**Example – Protein folding**

* Reference space: enormous number of possible backbone conformations.
* Physical and chemical constraints (steric clashes, bond angles, hydrophobic effects) drastically reduce  $ |\mathcal{S}_{\text{accessible}}(t)| $ .
* The native fold corresponds to a regime where accessible conformations are extremely few;  $ C(t) $  is very close to  $ C_{\max} $ .

**Types of constraints**

| Type          | Example                                  | System                    |
| ------------- | ---------------------------------------- | ------------------------- |
| Physical      | Conservation laws, steric exclusions     | Physical systems          |
| Structural    | Membrane integrity, lattice connectivity | Biological, materials     |
| Informational | Genetic code, protocols                  | Biological, communication |
| Logical       | Game rules, algorithmic invariants       | Games, computation        |
| Social        | Laws, norms, institutional rules         | Societies                 |

Constraints are not merely limitations—they are the **enablers** of structure, information, and stability.

---

### 2.5 Primitive 5: State (S)

**Informal definition**
State is the complete configuration of a system at time  $ t $ .

**Formal representation**

$$
S(t) \in \mathcal{S}
$$

where  $ \mathcal{S} $  is the state space (discrete, continuous, or hybrid).

**Key properties**

* **Completeness**: Given  $ S(t) $  and  $ F(S,t) $ , we can specify  $ S(t+\Delta t) $  in the model.
* **Composability**: Complex systems can be decomposed into subsystems whose states compose.
* **Coarse‑graining**: Different observational resolutions correspond to different effective state spaces  $ \mathcal{S}^{(\text{coarse})} $ .

**MWE – Langton’s Ant**

State can be defined as:

* Ant position  $ (x,y) $ ,
* Orientation  $ \theta \in {N, E, S, W} $ ,
* Grid cell colors  $ {c_{ij}} \in {0,1}^{N\times N} $ .

Then

$$
S(t) = \big(x_t, y_t, \theta_t, {c_{ij}(t)}\big)
$$

and the update rule is deterministic given  $ S(t) $ .

---

### 2.6 Relationships Among Primitives  *(v2.2)*

A useful dependency diagram:

```text
Constraint (C,  S_accessible ,  C(t) )
        ──→  Information (H,  I_gain)
           ↑               ↓
           │           State (S)
           │               ↓
      Time (T)  ←──  Force (F)
```

Key relationships:

1. **Constraints enable information**
   Given a finite reference  $ \mathcal{S} $ , constraints determine  $ \mathcal{S}_{\text{accessible}}(t) $  and cap entropy:

   $$
   H(S_t) \le \log \big|\mathcal{S}_{\text{accessible}}(t)\big|
   $$

   This is Law 2 in its simplest form.

2. **Information describes states**
   2.2 defines entropy  $ H $  and information gain  $ I_{\text{gain}} $  as functions of probability distributions over  $ \mathcal{S}_{\text{accessible}}(t) $ .

3. **Forces change states**
   Law 1 enforces  $ \frac{dS}{dt} = \alpha F(S,t) $  (or potential‑driven variants).

4. **Time orders change**
   Time indexes the sequence  $ {S(t)} $  and thus the accumulation of constraints  $ C(t) $ .

5. **Constraint accumulation**
   In closed, near‑equilibrium regimes,  $ C(t) $  tends to increase on long time scales (Law 4), reducing  $ H_{\max}(t) $  and framing the possible  $ I_{\text{gain}} $ .

Removing any primitive collapses the ability to describe evolution as “directed change of constrained states over time with measurable information”.

---

## 3. Derived Laws and Dependency Chain (v2.2)

We restate the six laws in their v2.2 form, highlighting assumptions and dependencies.

### 3.1 Law 1: Force Directionality

**Statement**
In any system with a defined force field  $ F $ , the instantaneous direction of state change aligns with  $ F(S,t) $  itself (or with  $ -\nabla V(S,t) $  when a potential  $ V $  exists).

**Formulation**

$$
\frac{dS}{dt} = \alpha F(S,t),
\quad \alpha > 0
$$

If a potential  $ V $  exists with  $ F = -\nabla V $ :

$$
\frac{dS}{dt} = -\alpha \nabla V(S,t)
$$

**Interpretation**

* This is essentially a formalization of “force is directed influence causing state change”.
* $ \nabla F $  (a Jacobian) describes spatial variation of the force field; it does **not** determine the basic direction of motion. v2.2 eliminates earlier abuses of  $ \nabla F $  for directionality.

**Examples**

* Gradient descent in ML:  $ F = -\nabla L(w) $ ,  $ \frac{dw}{dt} = -\alpha \nabla L(w) $ .
* Physical drift:  $ F = -\nabla U(x) $ ,  $ \frac{dx}{dt} = -\mu \nabla U(x) $ .

Momentum and other second‑order schemes are included by expanding the state  $ S $  (e.g., position + velocity).

---

### 3.2 Law 2: Information Capacity Bound Under Constraints

**Statement**

For a finite reference state space  $ \mathcal{S} $  and accessible subset  $ \mathcal{S}_{\text{accessible}}(t) $  at time  $ t $ :

$$
0 \le H(S_t) \le \log \big|\mathcal{S}_{\text{accessible}}(t)\big|
$$

Using the scalar constraint measure

$$
C(t) = \log|\mathcal{S}| - \log\big|\mathcal{S}_{\text{accessible}}(t)\big|
$$

we get

$$
H(S_t) \le \log|\mathcal{S}| - C(t)
$$

and the total information gain between  $ t = 0 $  and  $ t $ :

$$
I_{\text{gain}}(0 \to t) = H(S_0) - H(S_t) \le C(t) - C(0)
$$

**Derivation**

* For any finite support of size  $ N $ , Shannon entropy satisfies  $ H \le \log N $ .
* At time  $ t $ , the support is  $ \mathcal{S}_{\text{accessible}}(t) $  with size  $ N_t $ , giving  $ H(S_t) \le \log N_t $ .
* Express  $ \log N_t = \log|\mathcal{S}| - C(t) $ , yielding the entropy bound.
* Compare  $ H(S_0) $  and  $ H(S_t) $  under a fixed reference  $ \mathcal{S} $  to bound  $ I_{\text{gain}} $ .

**Interpretation**

* Constraints shrink accessible state space; this reduces the maximum possible entropy and caps the total information gain about microstates.
* You cannot gain more information about which microstate you are in than the amount by which constraints have eliminated alternatives.

---

### 3.3 Law 3: Time Asymmetry of Force Application

**Statement**

Given a system evolution operator  $ \Phi $  and force field  $ F $ :

$$
S(t+\Delta t) = \Phi[S(t), F(t)]
$$

In general:

* Forward mapping is well‑defined: given  $ S(t) $  and  $ F(t) $ ,  $ S(t+\Delta t) $  is determined (deterministic or stochastic).
* Backward mapping is ill‑posed: many combinations of  $ S(t) $  and  $ F(t) $  can lead to the same  $ S(t+\Delta t) $ .

This breaks time‑reversal symmetry at the effective level.

**Sources of asymmetry**

* Coarse‑graining: multiple microstates correspond to the same macrostate.
* Constraint accumulation: forbidden transitions remove many past possibilities.
* Noise and dissipation: effectively irreversible at the coarse scale.

**Relation to thermodynamics**

* Time asymmetry in FIT parallels the Second Law: as constraints accumulate and accessible microstates shrink, many “past histories” become indistinguishable.

---

### 3.4 Law 4: Constraint Accumulation (Under Equilibrium Approach)

**Statement**

In sufficiently closed systems, under a fixed coarse‑graining and in regimes where the system approaches a statistical equilibrium, the scalar constraint measure  $ C(t) $  is non‑decreasing on long time scales:

$$
C(t+\Delta t) \ge C(t) - \varepsilon(t),
\quad \varepsilon(t) \to 0 \text{ as } t \to \infty
$$

**Assumptions**

* System is effectively closed on the time scales of interest.
* Coarse‑graining (state description) is fixed.
* Dynamics are in a regime that tends toward equilibrium rather than being driven far from equilibrium by external forcing.

**Interpretation**

* Many physical, biological, and social systems exhibit increasing structural constraints over time in late‑time regimes: patterns, codes, norms, and equilibria form and stabilize.
* Local fluctuations and constraint relaxations can occur, but the long‑time trend is toward higher  $ C(t) $ .

---

### 3.5 Law 5: Equilibrium Nirvana Condition (Frozen Attractors)

**Statement**

For systems whose coarse‑grained dynamics converge to *frozen* attractors (no appreciable change at the observation scale), the variance of the net force field at that scale satisfies:

$$
\sigma^2(F) \to 0
\quad \text{as} \quad
C(t) \to C_{\max}
$$

**Scope**

Applies to:

* Still‑lifes in cellular automata.
* Fixed‑point attractors in dynamical systems under given coarse‑graining.
* Systems where residual fluctuations are negligible at the chosen scale.

Does **not** cover:

* Noise‑sustained stationary states where micro‑forces remain large but macro‑statistics are stationary.
* Periodic or chaotic attractors unless suitably coarse‑grained.

**Interpretation**

* In the relevant coarse‑grained state space, near nirvana the system experiences almost no net forces that would drive it out of its attractor.
* Local micro‑fluctuations might exist but average to negligible net drive at the scale we care about.

---

### 3.6 Law 6 (Provisional): Equilibrium Information Efficiency Hypothesis

**Statement (hypothesis)**

In certain highly adapted system classes (e.g., genetic coding, mature communication protocols), near frozen nirvana states the ratio of “useful information”  $ I_{\text{useful}}(t) $  to constraint  $ C(t) $  approaches a class‑specific constant  $ k $ :

$$
\lim_{C(t) \to C_{\max}} \frac{I_{\text{useful}}(t)}{C(t)} = k
$$

**Assumptions**

* A clear, operational definition of  $ I_{\text{useful}} $  is available (e.g., predictive or task‑relevant information).
* The system has undergone long‑term adaptation or optimization.
* Constraints predominantly reflect design/selection rather than random accidents.

**Interpretation**

* In such systems, long‑run evolution pushes codes and structures toward characteristic efficiency levels (information per constraint).
* DNA coding efficiency vs. human language redundancy is an illustrative contrast, not a strict derivation.

Because it depends on strong additional assumptions, Law 6 is explicitly marked as a **provisional efficiency hypothesis** rather than a strict law.

---

### 3.7 Dependency Chain

We can now summarize the logical structure:

* **Tier 1 (primitive‑proximal)**

  * Law 1: Force Directionality (primitives F, S, T).
  * Law 2: Information Capacity Bound (primitives H/I, C).
  * Law 3: Time Asymmetry (F, S, T, C, plus coarse‑graining).

* **Tier 2 (composite under assumptions)**

  * Law 4: Constraint Accumulation (Law 2 + Law 3 + equilibrium assumptions).
  * Law 5: Equilibrium Nirvana Condition (Law 1 + Law 4).
  * Law 6: Equilibrium Information Efficiency (Law 2 + Law 5 + adaptation assumptions).

This hierarchy clarifies which claims are nearly tautological and which are substantive hypotheses requiring empirical support.

---

## 4. Falsifiable Propositions

We now introduce 18 propositions derived from the laws and primitives. They are organized to support empirical and computational testing.

### 4.1 Complete Proposition List (v2.2)

**Category A – Nirvana dynamics (P1–P6)**

* **P1 – Nirvana irreversibility**
  In closed systems where a coarse‑grained nirvana regime is defined by  $ \sigma^2(F) < \varepsilon $ , the probability of spontaneously returning to a high‑variance regime  $ \sigma^2(F) > k\varepsilon $  in a fixed finite time window, *without external constraint relaxation*, tends to zero as  $ C(t) \to C_{\max} $ .

* **P2 – Constraint monotonicity**
  In effectively closed systems under a fixed coarse‑graining and approaching equilibrium, the scalar constraint measure  $ C(t) $  is non‑decreasing on long time scales (up to small fluctuations).

* **P3 – Force variance decay family**
  For systems converging to a given nirvana attractor, the variance of the net force field  $ \sigma^2(F_t) $  decays according to a simple parametric family (e.g., exponential or power‑law) as  $ t \to \infty $ , defining “decay universality subclasses”.

* **P4 – Plateau detection**
  Nirvana‑like plateaus can be operationally detected by joint smallness of  $ |dH/dt| $ ,  $ |dC/dt| $ , and  $ \sigma^2(F) $  over a window  $ W $ .

* **P5 – Perturbation recovery**
  Among attractors in the same system, those with higher  $ C $  have shorter recovery times after small perturbations than those with lower  $ C $ , all else equal.

* **P6 – Multi‑stability**
  In systems with non‑convex constraint landscapes, multiple nirvana attractors (local maxima of  $ C $ ) can coexist, with measurable basins of attraction.

---

**Category B – Information–constraint relationships (P7–P12)**

* **P7 – Entropy capacity bound (discrete)**
  For any system with a discrete accessible state set  $ \mathcal{S}_{\text{accessible}}(t) $  at time  $ t $  and probability distribution  $ P_t $  over it, Shannon entropy satisfies:

  $$
  0 \le H(S_t) = -\sum_{s \in \mathcal{S}*{\text{accessible}}(t)} P_t(s)\log_2 P_t(s)
  \le \log_2 \big|\mathcal{S}*{\text{accessible}}(t)\big|
  $$

  Equality on the right holds iff  $ P_t $  is uniform. This is the standard capacity bound interpreted through FIT.

* **P8 – Compression limit / information efficiency**
  For a given substrate or coding scheme, there exists a characteristic information–constraint efficiency  $ k_{\text{sub}} $  such that in long‑run adapted systems on that substrate the ratio  $ I_{\text{useful}}/C $  saturates near  $ k_{\text{sub}} $ .

* **P9 – Redundancy emergence near nirvana**
  As systems approach nirvana, redundancy  $ R(t) = 1 - H_{\text{actual}}(t)/H_{\max}(t) $  tends to increase, as systems trade raw capacity for robustness.

* **P10 – Constraint estimator consistency**
  Different operational estimators of  $ C $  (e.g., “frozen degrees of freedom”, accessible state counts, compression‑based estimates) remain monotonically related within the same regime.

* **P11 – Phase transition signature in  $ I/C $ **
  Regime changes (phase transitions) are typically marked by sharp changes or peaks in statistics derived from  $ I/C $  (e.g., large derivatives, spikes in the time derivative, or changes in autocorrelation).

* **P12 – Information bottleneck / constraint reconfiguration**
  Sustained growth in useful information  $ I_{\text{useful}} $  in a fixed system boundary requires reconfiguration or increase of constraints  $ C $ . In stationary regimes with fixed  $ C(t) $ ,  $ I_{\text{useful}} $  cannot grow indefinitely.

---

**Category C – Universal scaling (P13–P18)**

* **P13 – Critical slowing down**
  In systems with a well‑defined phase transition controlled by a parameter that can be expressed or mapped to  $ C $ , the relaxation time  $ \tau $  diverges near a critical constraint value  $ C_{\text{critical}} $  as:

  $$
  \tau \propto |C - C_{\text{critical}}|^{-\nu}
  $$

  for some exponent  $ \nu $ .

* **P14 – Scale‑free fluctuations near criticality**
  In the same critical regimes, fluctuations in relevant observables exhibit approximate scale‑free (power‑law) behavior over a non‑trivial range of scales.

* **P15 – Universality classes in FIT terms**
  Systems with the same qualitative primitive signatures (dimensionality, constraint type, locality structure of  $ F $ ) fall into the same universality class and share critical exponents.

* **P16 – Constraint hierarchy and timescale separation**
  In multiscale systems, constraints form a hierarchy  $ C_{\text{total}} = \sum_i \alpha_i C_i $  with  $ \alpha_1 > \alpha_2 > \dots $ , and higher‑level constraints evolve on slower timescales while modulating lower‑level constraints.

* **P17 – Dimensional collapse**
  As constraints accumulate, the effective intrinsic dimension of the system’s trajectory manifold in state space decreases, with long‑run dynamics concentrating on lower‑dimensional manifolds.

* **P18 – Timescale separation near attractors**
  Near nirvana or strong attractors, fast variables (forces, micro‑fluctuations) equilibrate quickly, while slow variables (constraints, coarse‑grained order parameters) evolve over much longer timescales.

---

### 4.2 Detailed Analysis: Three Exemplar Propositions

#### 4.2.1 P1 – Nirvana Irreversibility (v2.2)

**Statement**

For any closed system with state space  $ \mathcal{S} $  and scalar constraint  $ C(t) $ , define a nirvana regime by

$$
\sigma^2(F,t) < \varepsilon
$$

for small  $ \varepsilon > 0 $  under a fixed coarse‑graining. In the absence of external constraint relaxation (i.e.,  $ C(t+\Delta t) \ge C(t) $ ), the probability that the system spontaneously returns to a high‑variance regime  $ \sigma^2(F,t+\Delta t) > k\varepsilon $  in a finite time window is bounded by a function  $ g $  that decreases with “distance to maximal constraint”:

$$
P\big[
\sigma^2(F,t+\Delta t) > k\varepsilon
\mid
\sigma^2(F,t) < \varepsilon
\big]
\le
g\big(C_{\max} - C(t), \Delta t\big)
$$

with

$$
\lim_{C(t) \to C_{\max}} g\big(C_{\max} - C(t), \Delta t\big) = 0
$$

for fixed  $ \Delta t $ .

**Interpretation**

* The closer a system is to maximum constraint  $ C_{\max} $ , the smaller the chance of spontaneous large excursions in force variance without external interventions.
* In many statistical mechanics models  $ g $  is approximately exponential (Boltzmann‑like), but we do not hard‑code that form into P1.

**Computational test – Game of Life**

* Identify still‑lifes or long‑lived oscillators where  $ \sigma^2(F) $  falls below threshold  $ \varepsilon $ .
* Continue simulation for a large number of steps without external perturbations.
* Measure frequency of large excursions  $ \sigma^2(F) > k\varepsilon $ .
* Estimate  $ C(t) $  via fraction of cells that have stabilized; check whether excursions vanish as  $ C(t) $  approaches its plateau.

A robust observation of frequent spontaneous departures from low variance at high  $ C $  would challenge P1 (and correspondingly, the interpretation of nirvana).

---

#### 4.2.2 P7 – Entropy Capacity Bound (Discrete)

**Statement**

For any discrete system with accessible state set  $ \mathcal{S}_{\text{accessible}}(t) $  at time  $ t $  and probability distribution  $ P_t $  over it,

$$
0 \le H(S_t) = -\sum_{s \in \mathcal{S}*{\text{accessible}}(t)} P_t(s)\log_2 P_t(s)
\le \log_2 \big|\mathcal{S}*{\text{accessible}}(t)\big|
$$

Equality on the right holds iff  $ P_t $  is uniform.

**Significance**

* This is a standard property of Shannon entropy, reinterpreted in FIT language.
* Violations can only occur via mis‑defining  $ \mathcal{S}_{\text{accessible}} $  or incorrectly estimating  $ P_t $ .

**Computational toy test**

For binary strings:

* Reference space  $ \mathcal{S} = {0,1}^{10} $ .
* Apply constraints by fixing 3 bits; accessible state set size  $ 2^7 $ .
* Sample strings uniformly from the constrained set; estimate entropy  $ H(S_t) $ .
* Check  $ H(S_t) \le 7 $  bits.

If estimated  $ H(S_t) $  significantly exceeds  $ \log_2 |\mathcal{S}_{\text{accessible}}| $ , either:

* The estimator is flawed, or
* $ \mathcal{S}_{\text{accessible}} $  has been mis‑specified.

This proposition is primarily a consistency check for how constraints and entropy are operationalized in FIT applications.

---

#### 4.2.3 P13 – Critical Slowing Down

**Statement**

In systems with a phase transition controlled by a scalar parameter that can be expressed or monotonically related to  $ C $ , the relaxation time  $ \tau $  diverges near a critical constraint  $ C_{\text{critical}} $ :

$$
\tau \propto |C - C_{\text{critical}}|^{-\nu}
$$

for some  $ \nu > 0 $ .

**Assumptions**

* There exists a control parameter  $ \lambda $  (e.g., temperature) with  $ C = f(\lambda) $  monotone near the transition.
* Relaxation dynamics can be characterized by a single dominant  $ \tau $  (e.g., autocorrelation time of an order parameter).
* As  $ \lambda \to \lambda_c $  (critical point),  $ |F| $  at relevant scales tends to zero, slowing relaxation.

**Interpretation**

* P13 is a FIT restatement of standard critical slowing in statistical mechanics, with  $ C $  playing the role of a generalized control parameter.
* It becomes nontrivial when used to predict criticality in non‑physical systems (e.g., cognitive, social, or learning systems).

---

### 4.3 Validation Matrix

We classify propositions by difficulty (computational tractability) and evidence type (mathematical, computational, empirical):

| Difficulty | Mathematical                 | Computational                | Empirical                        |
| ---------- | ---------------------------- | ---------------------------- | -------------------------------- |
| **Easy**   | P7 (entropy capacity bound)  | P1 (GoL nirvana)             | P9 (redundancy trend)            |
|            | P10 (estimator monotonicity) | P2 (late‑time  $ C $  trend) | P14 (simple lab systems)         |
|            | P12 (information bottleneck) | P4 (plateau detection)       |                                  |
| **Medium** | P8 (compression limits)      | P3 (decay family)            | P13 (physical critical systems)  |
|            | P11 (transition signatures)  | P5 (recovery vs.  $ C $ )    | P15 (universality across models) |
|            | P16 (constraint hierarchy)   | P6 (multi‑stability)         |                                  |
| **Hard**   | P15 (universality proof)     | P17 (dimensional collapse)   | P13 (biological/cognitive)       |
|            | P18 (timescale separation)   | P18 (complex optimizers)     | P16–P18 in real data             |

This matrix guides the validation roadmap.

---

### 4.4 Falsification Strategy

FIT is scientific only if it can fail. We distinguish:

* **Direct falsification**
  A proposition is found to be clearly false under well‑specified conditions (e.g.,  $ H(S_t) > \log|\mathcal{S}_{\text{accessible}}| $  with correct support). This forces refinement or rejection.

* **Scope limitation**
  A proposition fails in certain domains but holds in others; the proposition is revised to a narrower scope and documented as such.

* **Quantitative refinement**
  Qualitative patterns hold but functional forms (e.g., exponential vs. power‑law) are incorrect; the functional form is updated while maintaining the overall structure.

We explicitly avoid:

* Redefining primitives post hoc to save a prediction.
* Invoking unmeasurable quantities to evade falsification.
* Relegating clear counterexamples to “exceptions” without adjusting the theory.

---

## 5. Validation Roadmap: Computational Testbeds

We prioritize systems with known rules and full state observability.

### 5.1 Conway’s Game of Life (GoL)

**Why GoL?**

* Deterministic, fully specified rules.
* Rich phenomenology: still‑lifes, oscillators, spaceships, chaos.
* Supports direct measurement of  $ F $ ,  $ H $ ,  $ C $ .

**Primitive mapping**

* $ S(t) $ : binary grid.
* $ T $ : integer generations.
* $ F $ : local “tendency” to flip given neighbor counts.
* $ H $ : Shannon entropy over coarse‑grained patterns (e.g., 2×2 blocks).
* $ C $ : fraction of cells that have remained unchanged over a sliding window.

**Example Python skeleton**

```python
import numpy as np
from scipy.ndimage import convolve
from collections import Counter

class GameOfLife:
    def __init__(self, size=100):
        self.grid = np.random.randint(0, 2, (size, size))
        self.history = [self.grid.copy()]

    def step(self):
        kernel = np.array([[1,1,1],
                           [1,0,1],
                           [1,1,1]])
        neighbors = convolve(self.grid, kernel, mode='wrap')

        birth = (self.grid == 0) & (neighbors == 3)
        survival = (self.grid == 1) & ((neighbors == 2) | (neighbors == 3))
        self.grid = (birth | survival).astype(int)

        self.history.append(self.grid.copy())

    def measure_force_variance(self):
        kernel = np.array([[1,1,1],
                           [1,0,1],
                           [1,1,1]])
        neighbors = convolve(self.grid, kernel, mode='wrap')

        force = np.zeros_like(self.grid, dtype=float)
        # Force proxy: deviation from “stable” neighbor counts
        force[self.grid == 0] = 3 - neighbors[self.grid == 0]
        force[self.grid == 1] = neighbors[self.grid == 1] - 2.5

        return np.var(force)

    def measure_entropy(self):
        blocks = []
        H, W = self.grid.shape
        for i in range(0, H - 1, 2):
            for j in range(0, W - 1, 2):
                block = tuple(self.grid[i:i+2, j:j+2].flatten())
                blocks.append(block)

        counts = Counter(blocks)
        probs = np.array(list(counts.values()), dtype=float)
        probs /= probs.sum()

        return -np.sum(probs * np.log2(probs + 1e-12))

    def measure_constraints(self, window=50):
        if len(self.history) < window:
            return 0.0
        recent = np.array(self.history[-window:])
        var_per_cell = np.var(recent, axis=0)
        constrained = np.sum(var_per_cell == 0.0)
        return constrained / self.grid.size
```

**Testing P1 (nirvana irreversibility)**

```python
def test_P1_nirvana_irreversibility(size=50, epsilon=1e-2, k=10.0,
                                    burn_in=1000, follow_up=1000):
    gol = GameOfLife(size=size)

    # Burn in until we detect a low-force-variance regime
    nirvana_gen = None
    for gen in range(burn_in):
        gol.step()
        sigma_F = gol.measure_force_variance()
        if sigma_F < epsilon:
            nirvana_gen = gen
            break

    if nirvana_gen is None:
        print("No nirvana detected in burn-in.")
        return None

    print(f"Nirvana detected at generation {nirvana_gen}, sigma_F ≈ {sigma_F:.4f}")

    # Follow-up: check for large excursions
    for _ in range(follow_up):
        gol.step()
        sigma_F = gol.measure_force_variance()
        if sigma_F > k * epsilon:
            print(f"P1 FALSIFIED: large excursion sigma_F={sigma_F:.4f}")
            return False

    print("P1 SUPPORTED in this run: no large excursions from nirvana.")
    return True
```

**Testing P2 (late‑time constraint trend)**

```python
def test_P2_constraint_monotonicity(size=50, steps=500, window=50, burn_in=100):
    gol = GameOfLife(size=size)
    C_values = []

    for gen in range(steps):
        gol.step()
        C = gol.measure_constraints(window=window)
        C_values.append(C)

    late = C_values[burn_in:]
    violations = sum(late[i+1] < late[i] for i in range(len(late)-1))
    violation_rate = violations / max(1, len(late) - 1)

    print(f"Late-phase C violation rate: {violation_rate:.2%}")
    if violation_rate < 0.05:
        print("P2 SUPPORTED (approximate non-decrease of C).")
        return True
    else:
        print("P2 CHALLENGED (frequent C decreases).")
        return False
```

**Testing P7 (entropy capacity bound)**

We need a rough proxy for  $ |\mathcal{S}_{\text{accessible}}| $ . A very crude approximation is:

* Treat each cell as either “frozen” (never changing over the window) or “free”.
* If a fraction  $ C(t) $  of cells are frozen, treat the remaining  $ (1-C(t))N^2 $  cells as independent bits.
* Then approximate  $ |\mathcal{S}_{\text{accessible}}| \approx 2^{(1-C)N^2} $ , so:

$$
H_{\max}(t) \approx (1-C(t)) N^2
$$

P7 then demands  $ H(S_t) \le H_{\max}(t) $  (up to estimation error).

```python
def test_P7_entropy_capacity_bound(size=30, steps=200, window=50, tol_factor=1.05):
    gol = GameOfLife(size=size)

    for gen in range(steps):
        gol.step()
        H = gol.measure_entropy()
        C = gol.measure_constraints(window=window)

        N = size
        free_bits = (1.0 - C) * (N ** 2)
        H_max = free_bits  # log2(2^(free_bits)) = free_bits

        if H > H_max * tol_factor:
            print(f"P7 VIOLATED at gen {gen}: H={H:.2f} > H_max={H_max:.2f}")
            return False

    print("P7 SUPPORTED within tolerance in this run.")
    return True
```

This is intentionally rough; the point is to check that operational measures of  $ H $  do not systematically exceed an operational estimate of  $ H_{\max} $ .

---

### 5.2 Langton’s Ant

**Why Langton’s Ant?**

* Single agent with extremely simple rules.
* Exhibits a well‑known phase transition from chaotic wandering to a “highway” (regular trajectory).
* Ideal for testing P11 (transition signatures) and P3 (force variance decay).

**Core dynamics**

* Grid of black/white cells.
* At each step, the ant turns right on white, left on black, flips the cell color, and moves forward.

**FIT mapping**

* $ S(t) $ : ant position + orientation + grid colors.
* $ F $ : effective directional tendency (step direction).
* $ C $ : trajectory predictability (e.g., R² of a linear fit to recent positions).
* $ I $ : roughly, diversity of visited cell colors or patterns.

**Skeleton implementation**

```python
from sklearn.linear_model import LinearRegression

class LangtonsAnt:
    def __init__(self, size=200):
        self.grid = np.zeros((size, size), dtype=int)  # 0=white, 1=black
        self.pos = np.array([size // 2, size // 2])
        self.dir = 0  # 0=N,1=E,2=S,3=W
        self.history = [self.pos.copy()]

    def step(self):
        x, y = self.pos
        if self.grid[x, y] == 0:
            self.dir = (self.dir + 1) % 4
            self.grid[x, y] = 1
        else:
            self.dir = (self.dir - 1) % 4
            self.grid[x, y] = 0

        if self.dir == 0:
            x -= 1
        elif self.dir == 1:
            y += 1
        elif self.dir == 2:
            x += 1
        else:
            y -= 1

        H, W = self.grid.shape
        self.pos = np.array([x % H, y % W])
        self.history.append(self.pos.copy())

    def measure_force_alignment(self, window=100):
        if len(self.history) < window + 1:
            return 0.0
        recent = np.array(self.history[-(window+1):])
        displacements = np.diff(recent, axis=0)
        norms = np.linalg.norm(displacements, axis=1)
        valid = norms > 0
        if valid.sum() < 2:
            return 0.0
        v = displacements[valid]
        dots = np.sum(v[1:] * v[:-1], axis=1)
        norms_prod = np.linalg.norm(v[1:], axis=1) * np.linalg.norm(v[:-1], axis=1)
        cosines = dots / (norms_prod + 1e-12)
        return np.mean(cosines)

    def measure_trajectory_constraint(self, window=200):
        if len(self.history) < window:
            return 0.0
        recent = np.array(self.history[-window:])
        X = np.arange(window).reshape(-1, 1)
        model = LinearRegression()
        model.fit(X, recent)
        r2 = model.score(X, recent)
        return max(0.0, r2)
```

**Testing P11 – Phase transition signature in  $ I/C $ **

We approximate  $ I $  as the standard deviation of grid states (simple proxy) and  $ C $  as  $ R^2 $  of a linear trajectory fit.

```python
def test_P11_langton(max_steps=15000, sample_every=100):
    ant = LangtonsAnt(size=200)
    records = []

    for step in range(max_steps):
        ant.step()
        if step % sample_every == 0 and step > 0:
            I_proxy = np.std(ant.grid.flatten())
            C = ant.measure_trajectory_constraint(window=200)
            if C > 1e-3:
                records.append((step, I_proxy / C))

    if len(records) < 3:
        print("Insufficient data for P11.")
        return None

    steps, ratios = zip(*records)
    ratios = np.array(ratios)
    d_ratio = np.abs(np.diff(ratios))
    idx = np.argmax(d_ratio)
    transition_step = steps[idx]

    print(f"Max |Δ(I/C)| at step ≈ {transition_step}")
    # Known: highway emerges around 10k steps (on large grids)
    if 8000 <= transition_step <= 12000:
        print("P11 SUPPORTED (transition signature near expected regime).")
        return True
    else:
        print("P11 INCONCLUSIVE / CHALLENGED (signature off).")
        return None
```

**Testing P3 – Force variance decay post‑transition**

After the highway emerges, the ant’s step direction becomes highly aligned; variance of “force” proxy should decay.

```python
def test_P3_langton(max_steps=15000, sample_every=100, post_start=10000):
    ant = LangtonsAnt(size=200)
    records = []

    for step in range(max_steps):
        ant.step()
        if step % sample_every == 0 and step >= post_start:
            align = ant.measure_force_alignment(window=100)
            var_force = 1.0 - np.abs(align)  # high alignment → low variance
            records.append((step - post_start, var_force))

    if len(records) < 5:
        print("Insufficient post-transition data for P3.")
        return None

    times, vars_ = zip(*records)
    times = np.array(times, dtype=float)
    vars_ = np.array(vars_, dtype=float)
    log_v = np.log(vars_ + 1e-8)
    slope, intercept = np.polyfit(times, log_v, 1)
    lambda_est = -slope
    print(f"Estimated exponential decay rate λ ≈ {lambda_est:.6f}")
    if lambda_est > 0:
        print("P3 SUPPORTED (force variance decays).")
        return True
    else:
        print("P3 CHALLENGED (no decay).")
        return False
```

---

### 5.3 Cross‑System Strategy

After initial tests in GoL and Langton’s Ant, we extend to:

* **Lattice models** (e.g., Ising): P13–P15.
* **Continuous dynamical systems**: P3, P5, P17.
* **Learning systems** (RL/SGD): P11, P12, P18.
* **Empirical biological and socio‑economic systems**: P2, P5, P13.

Success is graded by how many propositions survive across this spectrum.

---

## 6. Related Work

(Shortened to key points.)

### 6.1 Free Energy Principle (FEP) and Active Inference

* FEP posits free energy minimization in systems with Markov blankets.
* FIT generalizes: FEP’s free energy becomes a particular choice of force function  $ F(S) $ .
* FIT is substrate‑agnostic and does not require blankets; FEP is then an important special case for cognitive systems.

### 6.2 Constructor Theory

* Constructor Theory emphasizes possible vs. impossible transformations, effectively describing constraints.
* In FIT terms, it primarily characterizes  $ C $ ; FIT adds explicit dynamics via  $ F $ ,  $ T $ , and  $ H $ .
* Integration: constructor‑theoretic statements define the allowed  $ \mathcal{S}_{\text{accessible}} $ , while FIT predicts dynamics inside that space.

### 6.3 Adami‑Style Physical Complexity

* Defines complexity as information genomes encode about environments.
* FIT generalizes this by allowing any state component (not just genomes) to carry environmental information.
* Adami complexity becomes a special case where  $ S $  is a genome and  $ I_{\text{useful}} $  is mutual information with environment.

### 6.4 Wolfram’s Computational Universe

* Offers rich examples of emergent complexity (cellular automata).
* FIT explains *why* certain classes (e.g., “Class 4”) display critical‑like behavior in terms of  $ F $ ,  $ C $ ,  $ H $ .
* Computational irreducibility remains, but FIT targets qualitative laws instead of exact trajectory prediction.

### 6.5 Integrated Information Theory (IIT)

* IIT attempts to formalize consciousness as integrated information  $ \Phi $ .
* FIT can be seen as providing a more general information–constraint–force background.
* IIT might be expressible as specific constraints plus an  $ I_{\text{useful}} $  definition in FIT.

---

## 7. Applications

### 7.1 AI Safety: Alignment as Nirvana

* Idea: design reward and architecture so that aligned behavior corresponds to a nirvana state with low  $ \sigma^2(F) $  and high  $ C $ .
* Once reached, P1 suggests that escaping alignment requires constraint relaxation, which can be monitored and controlled.
* This directly suggests “alignment‑locking” mechanisms and diagnostics based on monitoring  $ C(t) $  and  $ \sigma^2(F) $ .

### 7.2 Institutional Design

* Institutions = constraint accumulation processes.
* FIT suggests tuning trade‑offs between stability (high  $ C $ , low  $ \sigma^2(F) $ ) and adaptability (room to increase  $ I_{\text{useful}} $ ).
* Tools: sunset clauses, meta‑constraints, and dynamic constraint layers informed by Law 4 and P5.

### 7.3 Complexity Science and Early Warning Signals

* P13 provides a generic early‑warning framework: monitor relaxation times and  $ \tau $  scaling to anticipate phase transitions.
* Applications: ecosystems, climate, financial markets, neural systems.

### 7.4 Material and Code Design

* Design self‑assembling systems so that desired configurations are high‑C nirvana states with minimal  $ \sigma^2(F) $ .
* Applies to DNA origami, protein design, and resilient software architectures.

---

## 8. Discussion and Limitations

### 8.1 Achievements

* A minimal primitive set (F, I/H, T, C, S).
* A clear Tier 1 / Tier 2 law hierarchy.
* A concrete set of testable propositions.
* A unifying perspective connecting diverse existing frameworks.

### 8.2 Limitations

* Continuous‑time, quantum, and deeply multiscale generalizations remain to be fully developed.
* Law 6 is explicitly marked as provisional.
* Operational definitions of  $ C(t) $  and  $ I_{\text{useful}} $  can be subtle and domain‑dependent.

### 8.3 Alternative Formulations

* Potential‑first instead of force‑first.
* Information‑first variants where  $ F $  arises as an information gradient.
* Category‑theoretic reformulations to formalize compositionality and scale changes.

### 8.4 Sociological Factors

* As with any “unifying” framework, FIT will be scrutinized for overreach.
* Strong emphasis on falsifiability and clear propositions is intended to anchor it in standard scientific practice.

### 8.5 Future Work

* Complete computational validation for Tier 1 testbeds.
* Empirical tests in biology and learning systems.
* Development of a continuous‑time stochastic FIT formalism.
* Exploration of renormalization‑like schemes for  $ F $ ,  $ H $ ,  $ C $  under coarse‑graining.

---

## 9. Conclusion

We have proposed the FIT Framework v2.2 as a minimal axiomatic foundation for evolutionary dynamics. From five primitives we structured six laws and eighteen falsifiable propositions, together with a concrete validation roadmap.

The central message is:

> Evolution can be understood as constraint accumulation under force gradients in time, with information playing the role of measured distinction in constrained state space.

Whether FIT ultimately survives empirical stress or requires major revision, its value lies in making explicit what is often implicit—what must be assumed for many cross‑domain statements about “evolution”, “learning”, and “stability” to make sense.

---

## Acknowledgments and Disclosure

Large language models were used as tools to assist with drafting and language refinement. Conceptual content, interpretations, and responsibility for errors remain with the human author.

---

## References

(Abbreviated; same as in original draft, with numbering preserved.)

[1] Schrödinger, E. *What is Life?* Cambridge University Press, 1944.
[2] Landauer, R. “Irreversibility and heat generation in the computing process.” *IBM J. Res. Dev.*, 1961.
[3] Maynard Smith, J. *Evolution and the Theory of Games*. Cambridge University Press, 1982.
[4] Friston, K. “The free‑energy principle: a unified brain theory?” *Nat. Rev. Neurosci.*, 2010.
[7] Deutsch, D., Marletto, C. “Constructor theory of information.” *Proc. R. Soc. A*, 2015.
[10] Adami, C. et al. “Evolution of biological complexity.” *PNAS*, 2000.
[11] Wolfram, S. *A New Kind of Science*. Wolfram Media, 2002.
[12] Anfinsen, C. B. “Principles that govern the folding of protein chains.” *Science*, 1973.

(Full reference list can be expanded as needed.)

---

## Appendix A: Proposition Registry and Validation Record Format (v2.2)

This appendix defines a canonical proposition registry and a standard validation record format for the eighteen propositions (P1–P18).

```yaml
registry_version: "v2.2"
paper_version: "v2.2"
last_updated: "2025-12-25"
```

The goals:

1. Make it easy to register tests (code, data, parameters).
2. Make negative results first‑class citizens.
3. Allow automated aggregation of evidence across implementations.

### A.1 Paper‑Facing Summary Registry

Status legend:

* **Untested**
* **Partial**
* **Supported**
* **Falsified**
* **Scope‑limited**

| ID | Short name                        | Cluster | Scope preconditions (minimum)           | Boundary declaration (minimum)     | Default window  $ W $   | Default thresholds (example)                                | Primary testbeds        | Status   |       |                 |          |          |
| -- | --------------------------------- | ------- | --------------------------------------- | ---------------------------------- | ----------------------- | ----------------------------------------------------------- | ----------------------- | -------- | ----- | --------------- | -------- | -------- |
| P1 | Attractor persistence (nirvana)   | A       | Stationary regime; fixed estimators     | Closed system or fixed boundary    | $ W = 100\text{–}1000 $ | $ \sigma^2(F) < \varepsilon $ , exit if  $ > k\varepsilon $ | GoL, Langton’s Ant      | Untested |       |                 |          |          |
| P2 | Late‑time constraint non‑decrease | A       | Stationary regime; burn‑in defined      | Fixed boundary +  $ C $  estimator | $ W = 100\text{–}1000 $ | Violation rate  $ < 5% $                                    | GoL, Ant                | Untested |       |                 |          |          |
| P3 | Force‑variance decay family       | A       | Near attractor; decay regime identified | Fixed boundary +  $ F $  estimator | $ W = 100\text{–}1000 $ | Exponential/power‑law fit stable                            | GoL, Ant, optimizers    | Untested |       |                 |          |          |
| P4 | Plateau detection criterion       | A       | Detector parameters declared            | Fixed boundary                     | $ W = 100\text{–}1000 $ | Small  $                                                    | dH/dt                   | ,        | dC/dt | , \sigma^2(F) $ | GoL, Ant | Untested |
| P5 | Recovery time vs. constraint      | A       | Perturbation protocol fixed             | Perturbation boundary specified    | $ W = 100\text{–}1000 $ | $ \tau $  decreases with  $ C $                             | GoL, Ant, RL toy models | Untested |       |                 |          |          |
| P6 | Multi‑attractor basins            | A       | Non‑convexity established               | Boundary + init distribution fixed | $ W = 100\text{–}1000 $ | Basin measures reproducible                                 | Toy optimizers, CA      | Untested |       |                 |          |          |

| ID  | Short name                               | Cluster | Scope preconditions (minimum)    | Boundary declaration (minimum)  | Default  $ W $          | Default thresholds                                       | Primary testbeds           | Status   |                     |          |
| --- | ---------------------------------------- | ------- | -------------------------------- | ------------------------------- | ----------------------- | -------------------------------------------------------- | -------------------------- | -------- | ------------------- | -------- |
| P7  | Entropy capacity bound (discrete)        | B       | Discrete support defined         | Accessible set definition fixed | N/A                     | $ H(S) \le \log_2                                        | \mathcal{S}_{\text{acc}}   | $        | Finite‑state models | Untested |
| P8  | Predictive information saturation        | B       | Stationary regime                | Boundary fixed                  | $ W = 100\text{–}1000 $ | $ I_{\text{pred}} $  plateaus with  $ C $                | GoL, Ant, learning systems | Untested |                     |          |
| P9  | Compressibility increases near attractor | B       | Compression proxy declared       | Boundary fixed                  | $ W = 100\text{–}1000 $ | Compression ratio  $ \uparrow $  with  $ C $             | GoL, Ant                   | Untested |                     |          |
| P10 | Constraint estimator equivalence         | B       | ≥2  $ C $  estimators declared   | Boundary fixed                  | $ W = 100\text{–}1000 $ | Monotone correlation between estimates                   | GoL, Ant                   | Untested |                     |          |
| P11 | Regime‑change signatures in  $ I/C $     | B       | Transition definition fixed      | Boundary fixed                  | $ W = 100\text{–}1000 $ | Peaks in  $ d(I/C)/dt $  or autocorr                     | Langton’s Ant, others      | Untested |                     |          |
| P12 | Information growth needs  $ C $  change  | B       | $ I $  and  $ C $  metrics fixed | Boundary fixed                  | $ W = 100\text{–}1000 $ | Sustained  $ \Delta I > 0 $  implies  $ \Delta C \ne 0 $ | Learning systems           | Untested |                     |          |

| ID  | Short name                         | Cluster | Scope preconditions (minimum)                      | Boundary declaration (minimum) | Default  $ W $          | Default thresholds                            | Primary testbeds      | Status        |                              |          |
| --- | ---------------------------------- | ------- | -------------------------------------------------- | ------------------------------ | ----------------------- | --------------------------------------------- | --------------------- | ------------- | ---------------------------- | -------- |
| P13 | Critical slowing down              | C       | Transition region defined                          | Boundary fixed                 | Variable                | $ \tau \propto                                | C-C_c                 | ^{-\nu} $ fit | Ising, other critical models | Untested |
| P14 | Scale‑free fluctuations            | C       | Critical region defined                            | Boundary fixed                 | Variable                | Power‑law spectra in fluctuations             | Critical systems      | Untested      |                              |          |
| P15 | Universality within class          | C       | Class definition fixed                             | Boundary fixed                 | Variable                | Matching exponents across members             | System families       | Untested      |                              |          |
| P16 | Constraint hierarchy               | C       | Multiscale structure present                       | Boundary fixed                 | Variable                | Distinct timescales per layer                 | Multiscale models     | Untested      |                              |          |
| P17 | Dimensional collapse               | C       | Intrinsic‑dim estimator fixed                      | Boundary fixed                 | $ W = 100\text{–}1000 $ | Dimension  $ \downarrow $  as  $ C \uparrow $ | GoL, learning systems | Untested      |                              |          |
| P18 | Timescale separation near plateaus | C       | Definitions of  $ \tau_F $  and  $ \tau_C $  fixed | Boundary fixed                 | $ W = 100\text{–}1000 $ | $ \tau_F \ll \tau_C $  near nirvana           | GoL, Ant, optimizers  | Untested      |                              |          |

### A.2 Repository‑Facing Proposition Record Schema

A machine‑readable registry (e.g., YAML) is recommended. Sketch:

```yaml
registry_version: "v2.2"
paper_version: "v2.2"
last_updated: "2025-12-25"

propositions:
  - id: "P1"
    short_name: "Attractor persistence"
    cluster: "A"
    formal_statement_ref: "Section 4.2.1"
    scope_conditions:
      - "state representation S_t declared"
      - "stationary regime over measurement horizon"
      - "force estimator F declared"
      - "constraint estimator C declared"
    assumptions:
      - "system boundary fixed during run"
      - "no exogenous perturbation unless explicitly applied"
    boundary:
      description: "e.g., torus wrap-around grid"
      boundary_conditions: "periodic in both dimensions"
    state_representation:
      S_t: "full grid configuration"
      coarse_graining: "none"
    estimators:
      force:
        name: "local flip tendency"
        definition: "deviation from stable neighbor counts"
      constraint:
        - name: "frozen-cell fraction"
          definition: "fraction of cells unchanged in last W steps"
    measurement:
      window_W: 100
      thresholds:
        epsilon_force_var: 0.01
        k_multiplier: 10.0
    protocol:
      steps:
        - "initialize random grid"
        - "evolve until sigma^2(F) < epsilon"
        - "continue for W steps, recording sigma^2(F)"
      outputs_required:
        - "time series of sigma^2(F)"
        - "C(t) series"
    falsification:
      criterion: "significant fraction of runs show sigma^2(F) > k*epsilon without perturbation"
    replication:
      initialization_distribution: "Bernoulli(0.5) over grid cells"
      seeds_policy: "fixed list for reproducibility"
      num_runs: 100
      environment:
        language: "python"
        versions:
          - "python==3.11"
          - "numpy==1.x"
```

Similar entries can be defined for P2–P18.

---


